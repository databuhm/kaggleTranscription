{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/kaggle/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# all lightfm imports\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM, cross_validation\n",
    "from lightfm.evaluation import precision_at_k, auc_score # type: ignore\n",
    "\n",
    "# imports re for text cleaning\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# we will ignore pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all datasets and store them in pandas df\n",
    "base_path = './input/'\n",
    "df_answer_scores = pd.read_csv(\n",
    "    base_path + 'answer_scores.csv'\n",
    ")\n",
    "\n",
    "df_answers = pd.read_csv(\n",
    "    base_path + 'answers.csv',\n",
    "    parse_dates=['answers_date_added']\n",
    ")\n",
    "\n",
    "df_comments = pd.read_csv(\n",
    "    base_path + 'comments.csv'\n",
    ")\n",
    "\n",
    "df_emails = pd.read_csv(\n",
    "    base_path + 'emails.csv'\n",
    ")\n",
    "\n",
    "df_group_memberships = pd.read_csv(\n",
    "    base_path + 'group_memberships.csv'\n",
    ")\n",
    "\n",
    "df_groups = pd.read_csv(\n",
    "    base_path + 'groups.csv'\n",
    ")\n",
    "\n",
    "df_matches = pd.read_csv(\n",
    "    base_path + 'matches.csv'\n",
    ")\n",
    "\n",
    "df_professionals = pd.read_csv(\n",
    "    base_path + 'professionals.csv',\n",
    "    parse_dates=['professionals_date_joined']\n",
    ")\n",
    "\n",
    "df_question_scores = pd.read_csv(\n",
    "    base_path + 'question_scores.csv'\n",
    ")\n",
    "\n",
    "df_questions = pd.read_csv(\n",
    "    base_path + 'questions.csv',\n",
    "    parse_dates=['questions_date_added']\n",
    ")\n",
    "\n",
    "df_school_memberships = pd.read_csv(\n",
    "    base_path + 'school_memberships.csv'\n",
    ")\n",
    "\n",
    "df_students = pd.read_csv(\n",
    "    base_path + 'students.csv',\n",
    "    parse_dates=['students_date_joined']\n",
    ")\n",
    "\n",
    "df_tag_questions = pd.read_csv(\n",
    "    base_path + 'tag_questions.csv'\n",
    ")\n",
    "\n",
    "df_tag_users = pd.read_csv(\n",
    "    base_path + 'tag_users.csv'\n",
    ")\n",
    "\n",
    "df_tags = pd.read_csv(\n",
    "    base_path + 'tags.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7b2bb0fc0d384e298cffa6afde9cf6ab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7640a6e5d5224c8681cc58de860858f4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ce32e236fa9435183b2180fb213375c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fa30fe4c016043e382c441a7ef743bfb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71229eb293314c8a9e545057ecc32c93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  score\n",
       "0  7b2bb0fc0d384e298cffa6afde9cf6ab      1\n",
       "1  7640a6e5d5224c8681cc58de860858f4      5\n",
       "2  3ce32e236fa9435183b2180fb213375c      2\n",
       "3  fa30fe4c016043e382c441a7ef743bfb      0\n",
       "4  71229eb293314c8a9e545057ecc32c93      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answer_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14+00:00</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada720538c014e9b8a6dceed09385ee3</td>\n",
       "      <td>2aa47af241bf42a4b874c453f0381bd4</td>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>2018-05-01 14:19:08+00:00</td>\n",
       "      <td>&lt;p&gt;Hi. I joined the Army after I attended coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eaa66ef919bc408ab5296237440e323f</td>\n",
       "      <td>cbd8f30613a849bf918aed5c010340be</td>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>2018-05-02 02:41:02+00:00</td>\n",
       "      <td>&lt;p&gt;Dear Priyanka,&lt;/p&gt;&lt;p&gt;Greetings! I have answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a6b3749d391486c9e371fbd1e605014</td>\n",
       "      <td>7e72a630c303442ba92ff00e8ea451df</td>\n",
       "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
       "      <td>2017-05-10 19:00:47+00:00</td>\n",
       "      <td>&lt;p&gt;I work for a global company who values high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5229c514000446d582050f89ebd4e184</td>\n",
       "      <td>17802d94699140b0a0d2995f30c034c6</td>\n",
       "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
       "      <td>2017-10-13 22:07:33+00:00</td>\n",
       "      <td>I agree with Denise. Every single job I've had...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  ada720538c014e9b8a6dceed09385ee3  2aa47af241bf42a4b874c453f0381bd4   \n",
       "2  eaa66ef919bc408ab5296237440e323f  cbd8f30613a849bf918aed5c010340be   \n",
       "3  1a6b3749d391486c9e371fbd1e605014  7e72a630c303442ba92ff00e8ea451df   \n",
       "4  5229c514000446d582050f89ebd4e184  17802d94699140b0a0d2995f30c034c6   \n",
       "\n",
       "                answers_question_id        answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54 2016-04-29 19:40:14+00:00   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c 2018-05-01 14:19:08+00:00   \n",
       "2  eb80205482e4424cad8f16bc25aa2d9c 2018-05-02 02:41:02+00:00   \n",
       "3  4ec31632938a40b98909416bdd0decff 2017-05-10 19:00:47+00:00   \n",
       "4  2f6a9a99d9b24e5baa50d40d0ba50a75 2017-10-13 22:07:33+00:00   \n",
       "\n",
       "                                        answers_body  \n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...  \n",
       "1  <p>Hi. I joined the Army after I attended coll...  \n",
       "2  <p>Dear Priyanka,</p><p>Greetings! I have answ...  \n",
       "3  <p>I work for a global company who values high...  \n",
       "4  I agree with Denise. Every single job I've had...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments_id</th>\n",
       "      <th>comments_author_id</th>\n",
       "      <th>comments_parent_content_id</th>\n",
       "      <th>comments_date_added</th>\n",
       "      <th>comments_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f30250d3c2ca489db1afa9b95d481e08</td>\n",
       "      <td>9fc88a7c3323466dbb35798264c7d497</td>\n",
       "      <td>b476f9c6d9cd4c50a7bacdd90edd015a</td>\n",
       "      <td>2019-01-31 23:39:40 UTC+0000</td>\n",
       "      <td>First, you speak to recruiters. They are train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca9bfc4ba9464ea383a8b080301ad72c</td>\n",
       "      <td>de2415064b9b445c8717425ed70fd99a</td>\n",
       "      <td>ef4b6ae24d1f4c3b977731e8189c7fd7</td>\n",
       "      <td>2019-01-31 20:30:47 UTC+0000</td>\n",
       "      <td>Most large universities offer study abroad pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c354f6e33956499aa8b03798a60e9386</td>\n",
       "      <td>6ed20605002a42b0b8e3d6ac97c50c7f</td>\n",
       "      <td>ca7a9d7a95df471c816db82ee758f57d</td>\n",
       "      <td>2019-01-31 18:44:04 UTC+0000</td>\n",
       "      <td>First, I want to put you at ease that the oppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73a6223948714c5da6231937157e4cb7</td>\n",
       "      <td>d02f6d9faac24997a7003a59e5f34bd3</td>\n",
       "      <td>c7a88aa76f5f49b0830bfeb46ba17e4d</td>\n",
       "      <td>2019-01-31 17:53:28 UTC+0000</td>\n",
       "      <td>Your question submission was great! I just wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55a89a9061d44dd19569c45f90a22779</td>\n",
       "      <td>e78f75c543e84e1c94da1801d8560f65</td>\n",
       "      <td>c7a88aa76f5f49b0830bfeb46ba17e4d</td>\n",
       "      <td>2019-01-31 14:51:53 UTC+0000</td>\n",
       "      <td>Thank you. I'm new to this site. I'm sorry if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comments_id                comments_author_id  \\\n",
       "0  f30250d3c2ca489db1afa9b95d481e08  9fc88a7c3323466dbb35798264c7d497   \n",
       "1  ca9bfc4ba9464ea383a8b080301ad72c  de2415064b9b445c8717425ed70fd99a   \n",
       "2  c354f6e33956499aa8b03798a60e9386  6ed20605002a42b0b8e3d6ac97c50c7f   \n",
       "3  73a6223948714c5da6231937157e4cb7  d02f6d9faac24997a7003a59e5f34bd3   \n",
       "4  55a89a9061d44dd19569c45f90a22779  e78f75c543e84e1c94da1801d8560f65   \n",
       "\n",
       "         comments_parent_content_id           comments_date_added  \\\n",
       "0  b476f9c6d9cd4c50a7bacdd90edd015a  2019-01-31 23:39:40 UTC+0000   \n",
       "1  ef4b6ae24d1f4c3b977731e8189c7fd7  2019-01-31 20:30:47 UTC+0000   \n",
       "2  ca7a9d7a95df471c816db82ee758f57d  2019-01-31 18:44:04 UTC+0000   \n",
       "3  c7a88aa76f5f49b0830bfeb46ba17e4d  2019-01-31 17:53:28 UTC+0000   \n",
       "4  c7a88aa76f5f49b0830bfeb46ba17e4d  2019-01-31 14:51:53 UTC+0000   \n",
       "\n",
       "                                       comments_body  \n",
       "0  First, you speak to recruiters. They are train...  \n",
       "1  Most large universities offer study abroad pro...  \n",
       "2  First, I want to put you at ease that the oppo...  \n",
       "3  Your question submission was great! I just wan...  \n",
       "4  Thank you. I'm new to this site. I'm sorry if ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our necessary funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_int_id(dataframe, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate unique integer id for users, questions and answers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    id_col_name : String \n",
    "        New integer id's column name.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dataframe\n",
    "        Updated dataframe containing new id column \n",
    "    \"\"\"\n",
    "    new_dataframe=dataframe.assign(\n",
    "        int_id_col_name=np.arange(len(dataframe))\n",
    "        ).reset_index(drop=True)\n",
    "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "def create_features(dataframe, features_name, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe which contains features\n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe\n",
    "    id_col_name: String\n",
    "        Column name which contains id of the question or\n",
    "        answer that the features will map to.\n",
    "        There are two possible values for this variable.\n",
    "        1. questions_id_num\n",
    "        2. professionals_id_num\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Series\n",
    "        A pandas series containing process features\n",
    "        that are ready for feed into lightfm.\n",
    "        The format of each value\n",
    "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "        Ex. -> (1, ['military', 'army', '5'])\n",
    "    \"\"\"\n",
    "\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = list(zip(dataframe[id_col_name], features))\n",
    "    return features\n",
    "\n",
    "def generate_feature_list(dataframe, features_name):\n",
    "    \"\"\"\n",
    "    Generate features list for mapping \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    features_name: List\n",
    "        List of feature columns name avaiable in dataframe. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of all features for mapping \n",
    "    \"\"\"\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    return features\n",
    "\n",
    "def calculate_auc_score(lightfm_model, interactions_matrix, \n",
    "                        question_features, professional_features): \n",
    "    \"\"\"\n",
    "    Measure the ROC AUC metric for a model. \n",
    "    A perfect score is 1.0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lightfm_model: LightFM model \n",
    "        A fitted lightfm model \n",
    "    interactions_matrix: \n",
    "        A lightfm interactions matrix \n",
    "    question_features, professional_features: \n",
    "        Lightfm features \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String containing AUC score \n",
    "    \"\"\"\n",
    "    score = auc_score( \n",
    "        lightfm_model, interactions_matrix, \n",
    "        item_features=question_features, \n",
    "        user_features=professional_features, \n",
    "        num_threads=4).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating unique integer id for users and q&a\n",
    "df_professionals = generate_int_id(df_professionals, 'professionals_id_num')\n",
    "df_students = generate_int_id(df_students, 'students_id_num')\n",
    "df_questions = generate_int_id(df_questions, 'questions_id_num')\n",
    "df_answers = generate_int_id(df_answers, 'answers_id_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataset\n",
    "\n",
    "# just dropna from tags \n",
    "df_tags = df_tags.dropna()\n",
    "df_tags['tags_tag_name'] = df_tags['tags_tag_name'].str.replace('#', '')\n",
    "\n",
    "# merge tag_questions with tags name\n",
    "# then group all tags for each question into single rows\n",
    "df_tags_question = df_tag_questions.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_questions_tag_id', right_on='tags_tag_id')\n",
    "df_tags_question = df_tags_question.groupby(\n",
    "    ['tag_questions_question_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_question = df_tags_question.rename(columns={'tags_tag_name': 'questions_tag_name'})\n",
    "\n",
    "# merge tag_users with tags name \n",
    "# then group all tags for each user into single rows \n",
    "# after that rename the tag column name \n",
    "df_tags_pro = df_tag_users.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
    "df_tags_pro = df_tags_pro.groupby(\n",
    "    ['tag_users_user_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_pro = df_tags_pro.rename(columns={'tags_tag_name': 'professionals_tag_name'})\n",
    "\n",
    "# merge professionals and questions tags with main merge_dataset \n",
    "df_questions = df_questions.merge(\n",
    "    df_tags_question, how='left',\n",
    "    left_on='questions_id', right_on='tag_questions_question_id')\n",
    "df_professionals = df_professionals.merge(\n",
    "    df_tags_pro, how='left',\n",
    "    left_on='professionals_id', right_on='tag_users_user_id')\n",
    "\n",
    "# merge questions with scores \n",
    "df_questions = df_questions.merge(\n",
    "    df_question_scores, how='left',\n",
    "    left_on='questions_id', right_on='id')\n",
    "# merge questions with students \n",
    "df_questions = df_questions.merge(\n",
    "    df_students, how='left',\n",
    "    left_on='questions_author_id', right_on='students_id')\n",
    "\n",
    "# merge answers with questions \n",
    "# then merge professionals and questions score with that \n",
    "df_merge = df_answers.merge(\n",
    "    df_questions, how='inner',\n",
    "    left_on='answers_question_id', right_on='questions_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_professionals, how='inner',\n",
    "    left_on='answers_author_id', right_on='professionals_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_question_scores, how='inner',\n",
    "    left_on='questions_id', right_on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate some features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some features for calculates weights\n",
    "# that will use with interaction matrix \n",
    "\n",
    "df_merge['num_of_ans_by_professional'] = df_merge.groupby(['answers_author_id'])['questions_id'].transform('count')\n",
    "df_merge['num_ans_per_ques'] = df_merge.groupby(['questions_id'])['answers_id'].transform('count')\n",
    "df_merge['num_tags_professional'] = df_merge['professionals_tag_name'].str.split(\",\").str.len()\n",
    "df_merge['num_tags_question'] = df_merge['questions_tag_name'].str.split(\",\").str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional line**: Convert dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['answers_date_added'] = pd.to_datetime(df_merge['answers_date_added']).dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_id_num</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>...</th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>id_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>num_of_ans_by_professional</th>\n",
       "      <th>num_ans_per_ques</th>\n",
       "      <th>num_tags_professional</th>\n",
       "      <th>num_tags_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>2016-07-31 15:35:54</td>\n",
       "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
       "      <td>2016-05-19 22:16:25+00:00</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-15 23:08:46</td>\n",
       "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
       "      <td>71</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-13 18:18:05</td>\n",
       "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
       "      <td>72</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-13 17:48:09+00:00</td>\n",
       "      <td>18373</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>computer-software</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3fc23809cda472780fc565334f35000</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>2018-08-14 10:37:01</td>\n",
       "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
       "      <td>102</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
       "      <td>2018-08-14 04:49:33+00:00</td>\n",
       "      <td>How should I prepare myself for my job search ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  f3519ab99a1a4a13a8a9ecb814287d2a  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  825f6e316a5f48328d6f8af831df9940  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  fb2c794175304c4caeb55e654270421f  a32736b04c27437da3078374d47af1b1   \n",
       "4  f3fc23809cda472780fc565334f35000  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                answers_question_id   answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  2016-04-29 19:40:14   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  2016-07-31 15:35:54   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  2018-04-15 23:08:46   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  2018-04-13 18:18:05   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  2018-08-14 10:37:01   \n",
       "\n",
       "                                        answers_body  answers_id_num  \\\n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...               0   \n",
       "1  <p>Hi Rodrigo!</p>\\n<p>The important thing to ...              11   \n",
       "2  <p>Congratulations on being interested in find...              71   \n",
       "3  <p>Hi Elisabeth! </p><p><br></p><p>If you are ...              72   \n",
       "4  <p>The most important thing that you can do is...             102   \n",
       "\n",
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  585ac233015447cc9e9a217044e515e1   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  5b751a8ee4a047f7a08ce9eb5e43e5a2   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-19 22:16:25+00:00   \n",
       "2 2018-04-12 17:13:45+00:00   \n",
       "3 2018-04-12 17:13:45+00:00   \n",
       "4 2018-08-14 04:49:33+00:00   \n",
       "\n",
       "                                     questions_title  ...  \\\n",
       "0                        Teacher   career   question  ...   \n",
       "1  what kind of  college could i go  to for a soc...  ...   \n",
       "2  What is the best way to prepare for studying e...  ...   \n",
       "3  What is the best way to prepare for studying e...  ...   \n",
       "4  How should I prepare myself for my job search ...  ...   \n",
       "\n",
       "  professionals_date_joined  professionals_id_num  \\\n",
       "0 2015-10-19 20:56:49+00:00                  2410   \n",
       "1 2015-10-19 20:56:49+00:00                  2410   \n",
       "2 2015-10-19 20:56:49+00:00                  2410   \n",
       "3 2018-04-13 17:48:09+00:00                 18373   \n",
       "4 2015-10-19 20:56:49+00:00                  2410   \n",
       "\n",
       "                  tag_users_user_id  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  a32736b04c27437da3078374d47af1b1   \n",
       "4  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0  engineering,computer-science,science,college,e...   \n",
       "1  engineering,computer-science,science,college,e...   \n",
       "2  engineering,computer-science,science,college,e...   \n",
       "3                                  computer-software   \n",
       "4  engineering,computer-science,science,college,e...   \n",
       "\n",
       "                               id_y  score_y num_of_ans_by_professional  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54        1                       1710   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289        1                       1710   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba        2                       1710   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba        2                          1   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff        1                       1710   \n",
       "\n",
       "  num_ans_per_ques num_tags_professional  num_tags_question  \n",
       "0                1                  12.0                3.0  \n",
       "1                1                  12.0                3.0  \n",
       "2                2                  12.0                3.0  \n",
       "3                2                   1.0                3.0  \n",
       "4                1                  12.0                4.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of answer per question : 58\n",
      "Maximum number of tags per professional : 82.0\n",
      "Maximum number of tags per question : 54.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum number of answer per question : \" + str(df_merge['num_ans_per_ques'].max()))\n",
    "print(\"Maximum number of tags per professional : \" + str(df_merge['num_tags_professional'].max()))\n",
    "print(\"Maximum number of tags per question : \" + str(df_merge['num_tags_question'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge answered questions tags with professional's tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge professionals previous answered\n",
    "# questions tags into professionals tags\n",
    "\n",
    "# select professionals answered questions tags\n",
    "# and stored as a dataframe\n",
    "professionals_prev_ans_tags = df_merge[['professionals_id', 'questions_tag_name']]\n",
    "\n",
    "# drop nulss values from that\n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
    "\n",
    "# because professionals answers multiple questions,\n",
    "# we group all of tags of each user into single row\n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.groupby(['professionals_id'])['questions_tag_name'].apply(','.join).reset_index()\n",
    "\n",
    "# drop duplicates tags from each professionals rows\n",
    "professionals_prev_ans_tags['questions_tag_name'] = (\n",
    "    professionals_prev_ans_tags['questions_tag_name'].str.split(',').apply(set).str.join(',')\n",
    ")\n",
    "\n",
    "# finally merge the dataframe with professionals dataframe\n",
    "df_professionals = df_professionals.merge(professionals_prev_ans_tags, how='left', on='professionals_id')\n",
    "\n",
    "# join professionals tags and their answered tags\n",
    "# we replace nan values with \"\"\n",
    "df_professionals['professional_all_tags'] = (\n",
    "    df_professionals[['professionals_tag_name', 'questions_tag_name']].apply(\n",
    "        lambda x: ','.join(x.dropna()),\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling null and duplicates values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling null values \n",
    "df_questions['score'] = df_questions['score'].fillna(0)\n",
    "df_questions['score'] = df_questions['score'].astype(int)\n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].fillna('No Tag')\n",
    "\n",
    "# remove duplicates tags from each questions \n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "# fill nan with 'No Tag' if any\n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].fillna('No Tag')\n",
    "\n",
    "# replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].replace('', 'No Tag')\n",
    "df_professionals['professionals_location'] = df_professionals['professionals_location'].fillna('No Location')\n",
    "df_professionals['professionals_industry'] = df_professionals['professionals_industry'].fillna('No Industry')\n",
    "\n",
    "# remove duplicates tags from each professionals \n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "# remove some null values from df_merge\n",
    "df_merge['num_ans_per_ques']  = df_merge['num_ans_per_ques'].fillna(0)\n",
    "df_merge['num_tags_professional'] = df_merge['num_tags_professional'].fillna(0)\n",
    "df_merge['num_tags_question'] = df_merge['num_tags_question'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_id_num</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>...</th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>id_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>num_of_ans_by_professional</th>\n",
       "      <th>num_ans_per_ques</th>\n",
       "      <th>num_tags_professional</th>\n",
       "      <th>num_tags_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>2016-07-31 15:35:54</td>\n",
       "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
       "      <td>2016-05-19 22:16:25+00:00</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-15 23:08:46</td>\n",
       "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
       "      <td>71</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-13 18:18:05</td>\n",
       "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
       "      <td>72</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-13 17:48:09+00:00</td>\n",
       "      <td>18373</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>computer-software</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3fc23809cda472780fc565334f35000</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>2018-08-14 10:37:01</td>\n",
       "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
       "      <td>102</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
       "      <td>2018-08-14 04:49:33+00:00</td>\n",
       "      <td>How should I prepare myself for my job search ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-19 20:56:49+00:00</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  f3519ab99a1a4a13a8a9ecb814287d2a  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  825f6e316a5f48328d6f8af831df9940  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  fb2c794175304c4caeb55e654270421f  a32736b04c27437da3078374d47af1b1   \n",
       "4  f3fc23809cda472780fc565334f35000  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                answers_question_id   answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  2016-04-29 19:40:14   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  2016-07-31 15:35:54   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  2018-04-15 23:08:46   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  2018-04-13 18:18:05   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  2018-08-14 10:37:01   \n",
       "\n",
       "                                        answers_body  answers_id_num  \\\n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...               0   \n",
       "1  <p>Hi Rodrigo!</p>\\n<p>The important thing to ...              11   \n",
       "2  <p>Congratulations on being interested in find...              71   \n",
       "3  <p>Hi Elisabeth! </p><p><br></p><p>If you are ...              72   \n",
       "4  <p>The most important thing that you can do is...             102   \n",
       "\n",
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  585ac233015447cc9e9a217044e515e1   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  5b751a8ee4a047f7a08ce9eb5e43e5a2   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-19 22:16:25+00:00   \n",
       "2 2018-04-12 17:13:45+00:00   \n",
       "3 2018-04-12 17:13:45+00:00   \n",
       "4 2018-08-14 04:49:33+00:00   \n",
       "\n",
       "                                     questions_title  ...  \\\n",
       "0                        Teacher   career   question  ...   \n",
       "1  what kind of  college could i go  to for a soc...  ...   \n",
       "2  What is the best way to prepare for studying e...  ...   \n",
       "3  What is the best way to prepare for studying e...  ...   \n",
       "4  How should I prepare myself for my job search ...  ...   \n",
       "\n",
       "  professionals_date_joined  professionals_id_num  \\\n",
       "0 2015-10-19 20:56:49+00:00                  2410   \n",
       "1 2015-10-19 20:56:49+00:00                  2410   \n",
       "2 2015-10-19 20:56:49+00:00                  2410   \n",
       "3 2018-04-13 17:48:09+00:00                 18373   \n",
       "4 2015-10-19 20:56:49+00:00                  2410   \n",
       "\n",
       "                  tag_users_user_id  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  a32736b04c27437da3078374d47af1b1   \n",
       "4  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0  engineering,computer-science,science,college,e...   \n",
       "1  engineering,computer-science,science,college,e...   \n",
       "2  engineering,computer-science,science,college,e...   \n",
       "3                                  computer-software   \n",
       "4  engineering,computer-science,science,college,e...   \n",
       "\n",
       "                               id_y  score_y num_of_ans_by_professional  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54        1                       1710   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289        1                       1710   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba        2                       1710   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba        2                          1   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff        1                       1710   \n",
       "\n",
       "  num_ans_per_ques num_tags_professional  num_tags_question  \n",
       "0                1                  12.0                3.0  \n",
       "1                1                  12.0                3.0  \n",
       "2                2                  12.0                3.0  \n",
       "3                2                   1.0                3.0  \n",
       "4                1                  12.0                4.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model in LightFM\n",
    "In this steps, we are going to build our lightFM model using lightFM python library. Firstly, we have to create lightFM `Dataset` for our model. LightFM Dataset class makes it really easy for us for creating `interaction matrix`, `weights` and `user/item features`.\n",
    "\n",
    "* `interaction matrix`: it is a matrix that contains user/item interactions or professional/question interactions.\n",
    "* `weights`: weight of interaction matrix. Less weight means less importance to that interaction matrix\n",
    "* `user/item features`: user/item features supplied as like this `(user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "\n",
    "If you want to how lightFM python library's dataset class works and how to use it, please go to this link [Building LightFM Datasets](http://https://lyst.github.io/lightfm/docs/examples/dataset.html).\n",
    "\n",
    "Then, after that we will be start building our lightFM model using LightFM class. LightFM class makes it really easy for making lightFM model. After that we will train our model by our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating features list for Dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating features list for mapping\n",
    "question_feature_list = generate_feature_list(\n",
    "    df_questions,\n",
    "    ['questions_tag_name'])\n",
    "\n",
    "professional_feature_list = generate_feature_list(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   professor\n",
       "1                     lecture\n",
       "2                     college\n",
       "3                        army\n",
       "4                    military\n",
       "                 ...         \n",
       "77191         law-enforcement\n",
       "77192                    java\n",
       "77193        computer-science\n",
       "77194    computer-engineering\n",
       "77195             programming\n",
       "Length: 77196, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        consulting\n",
       "1                                            resume\n",
       "2                                            No Tag\n",
       "3                                              bain\n",
       "4                                         emotional\n",
       "                            ...                    \n",
       "228831                                    mentoring\n",
       "228832    indirect-sales-(channel)-and-direct-sales\n",
       "228833                          women-in-leadership\n",
       "228834                              contact-centers\n",
       "228835                               communications\n",
       "Length: 228836, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate our weight value\n",
    "df_merge['total_weights'] = 1 / (\n",
    "    df_merge['num_ans_per_ques']\n",
    ")\n",
    "\n",
    "# creating features for feeding into lightfm\n",
    "df_questions['question_features'] = create_features(\n",
    "    df_questions, ['questions_tag_name'],\n",
    "    'questions_id_num'\n",
    ")\n",
    "\n",
    "df_professionals['professional_features'] = create_features(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'],\n",
    "    'professionals_id_num'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_id_num</th>\n",
       "      <th>tag_questions_question_id</th>\n",
       "      <th>questions_tag_name</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>students_id</th>\n",
       "      <th>students_location</th>\n",
       "      <th>students_date_joined</th>\n",
       "      <th>students_id_num</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>professor,lecture,college</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>Coimbatore, Tamil Nadu, India</td>\n",
       "      <td>2016-04-22 10:07:32+00:00</td>\n",
       "      <td>6890.0</td>\n",
       "      <td>(0, [professor, lecture, college])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
       "      <td>2016-05-20 16:48:25+00:00</td>\n",
       "      <td>I want to become an army officer. What can I d...</td>\n",
       "      <td>I am Priyanka from Bangalore . Now am in 10th ...</td>\n",
       "      <td>1</td>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>army,military</td>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>5</td>\n",
       "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
       "      <td>Providence, Rhode Island</td>\n",
       "      <td>2016-05-20 16:29:08+00:00</td>\n",
       "      <td>10189.0</td>\n",
       "      <td>(1, [army, military])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
       "      <td>f2c179a563024ccc927399ce529094b5</td>\n",
       "      <td>2017-02-08 19:13:38+00:00</td>\n",
       "      <td>Will going abroad for your first job increase ...</td>\n",
       "      <td>I'm planning on going abroad for my first job....</td>\n",
       "      <td>2</td>\n",
       "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
       "      <td>working-abroad,overseas</td>\n",
       "      <td>4ec31632938a40b98909416bdd0decff</td>\n",
       "      <td>2</td>\n",
       "      <td>f2c179a563024ccc927399ce529094b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-07 15:51:57+00:00</td>\n",
       "      <td>18023.0</td>\n",
       "      <td>(2, [working-abroad, overseas])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
       "      <td>2c30ffba444e40eabb4583b55233a5a4</td>\n",
       "      <td>2017-09-01 14:05:32+00:00</td>\n",
       "      <td>To become a specialist in business  management...</td>\n",
       "      <td>i hear business management is a hard way to ge...</td>\n",
       "      <td>3</td>\n",
       "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
       "      <td>networking,business</td>\n",
       "      <td>2f6a9a99d9b24e5baa50d40d0ba50a75</td>\n",
       "      <td>2</td>\n",
       "      <td>2c30ffba444e40eabb4583b55233a5a4</td>\n",
       "      <td>North Lauderdale, Florida</td>\n",
       "      <td>2017-09-01 14:02:02+00:00</td>\n",
       "      <td>20803.0</td>\n",
       "      <td>(3, [networking, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
       "      <td>aa9eb1a2ab184ebbb00dc01ab663428a</td>\n",
       "      <td>2017-09-01 02:36:54+00:00</td>\n",
       "      <td>Are there any scholarships out there for stude...</td>\n",
       "      <td>I'm trying to find scholarships for first year...</td>\n",
       "      <td>4</td>\n",
       "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
       "      <td>firstgeneration,scholarships,highschoolsenior,...</td>\n",
       "      <td>5af8880460c141dbb02971a1a8369529</td>\n",
       "      <td>2</td>\n",
       "      <td>aa9eb1a2ab184ebbb00dc01ab663428a</td>\n",
       "      <td>Tunnel Hill, Georgia</td>\n",
       "      <td>2017-09-01 02:29:06+00:00</td>\n",
       "      <td>20505.0</td>\n",
       "      <td>(4, [firstgeneration, scholarships, highschool...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c  acccbda28edd4362ab03fb8b6fd2d67b   \n",
       "2  4ec31632938a40b98909416bdd0decff  f2c179a563024ccc927399ce529094b5   \n",
       "3  2f6a9a99d9b24e5baa50d40d0ba50a75  2c30ffba444e40eabb4583b55233a5a4   \n",
       "4  5af8880460c141dbb02971a1a8369529  aa9eb1a2ab184ebbb00dc01ab663428a   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-20 16:48:25+00:00   \n",
       "2 2017-02-08 19:13:38+00:00   \n",
       "3 2017-09-01 14:05:32+00:00   \n",
       "4 2017-09-01 02:36:54+00:00   \n",
       "\n",
       "                                     questions_title  \\\n",
       "0                        Teacher   career   question   \n",
       "1  I want to become an army officer. What can I d...   \n",
       "2  Will going abroad for your first job increase ...   \n",
       "3  To become a specialist in business  management...   \n",
       "4  Are there any scholarships out there for stude...   \n",
       "\n",
       "                                      questions_body  questions_id_num  \\\n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...                 0   \n",
       "1  I am Priyanka from Bangalore . Now am in 10th ...                 1   \n",
       "2  I'm planning on going abroad for my first job....                 2   \n",
       "3  i hear business management is a hard way to ge...                 3   \n",
       "4  I'm trying to find scholarships for first year...                 4   \n",
       "\n",
       "          tag_questions_question_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c   \n",
       "2  4ec31632938a40b98909416bdd0decff   \n",
       "3  2f6a9a99d9b24e5baa50d40d0ba50a75   \n",
       "4  5af8880460c141dbb02971a1a8369529   \n",
       "\n",
       "                                  questions_tag_name  \\\n",
       "0                          professor,lecture,college   \n",
       "1                                      army,military   \n",
       "2                            working-abroad,overseas   \n",
       "3                                networking,business   \n",
       "4  firstgeneration,scholarships,highschoolsenior,...   \n",
       "\n",
       "                                 id  score                       students_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54      1  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c      5  acccbda28edd4362ab03fb8b6fd2d67b   \n",
       "2  4ec31632938a40b98909416bdd0decff      2  f2c179a563024ccc927399ce529094b5   \n",
       "3  2f6a9a99d9b24e5baa50d40d0ba50a75      2  2c30ffba444e40eabb4583b55233a5a4   \n",
       "4  5af8880460c141dbb02971a1a8369529      2  aa9eb1a2ab184ebbb00dc01ab663428a   \n",
       "\n",
       "               students_location      students_date_joined  students_id_num  \\\n",
       "0  Coimbatore, Tamil Nadu, India 2016-04-22 10:07:32+00:00           6890.0   \n",
       "1       Providence, Rhode Island 2016-05-20 16:29:08+00:00          10189.0   \n",
       "2                            NaN 2017-02-07 15:51:57+00:00          18023.0   \n",
       "3      North Lauderdale, Florida 2017-09-01 14:02:02+00:00          20803.0   \n",
       "4           Tunnel Hill, Georgia 2017-09-01 02:29:06+00:00          20505.0   \n",
       "\n",
       "                                   question_features  \n",
       "0                 (0, [professor, lecture, college])  \n",
       "1                              (1, [army, military])  \n",
       "2                    (2, [working-abroad, overseas])  \n",
       "3                        (3, [networking, business])  \n",
       "4  (4, [firstgeneration, scholarships, highschool...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_location</th>\n",
       "      <th>professionals_industry</th>\n",
       "      <th>professionals_headline</th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>questions_tag_name</th>\n",
       "      <th>professional_all_tags</th>\n",
       "      <th>professional_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
       "      <td>No Location</td>\n",
       "      <td>No Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-05 20:35:19+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consulting,resume</td>\n",
       "      <td>consulting,resume</td>\n",
       "      <td>(0, [consulting, resume])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
       "      <td>No Location</td>\n",
       "      <td>No Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-05 20:49:21+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>(1, [No Tag])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>No Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-18 17:31:26+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "      <td>consulting,consulting,consulting,consulting,co...</td>\n",
       "      <td>bain,emotional,residency,entrepreneurship,scho...</td>\n",
       "      <td>bain,emotional,residency,entrepreneurship,air-...</td>\n",
       "      <td>(2, [bain, emotional, residency, entrepreneurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
       "      <td>Boston, Massachusetts</td>\n",
       "      <td>No Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-11-09 20:39:29+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police,law,fashion-design,law-enforcement,crim...</td>\n",
       "      <td>fashion-design,police,law,law-enforcement,crim...</td>\n",
       "      <td>(3, [fashion-design, police, law, law-enforcem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
       "      <td>No Location</td>\n",
       "      <td>No Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-12-10 22:14:44+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Tag</td>\n",
       "      <td>(4, [No Tag])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   professionals_id professionals_location  \\\n",
       "0  9ced4ce7519049c0944147afb75a8ce3            No Location   \n",
       "1  f718dcf6d2ec4cb0a52a9db59d7f9e67            No Location   \n",
       "2  0c673e046d824ec0ad0ebe012a0673e4     New York, New York   \n",
       "3  977428d851b24183b223be0eb8619a8c  Boston, Massachusetts   \n",
       "4  e2d57e5041a44f489288397c9904c2b2            No Location   \n",
       "\n",
       "  professionals_industry professionals_headline professionals_date_joined  \\\n",
       "0            No Industry                    NaN 2011-10-05 20:35:19+00:00   \n",
       "1            No Industry                    NaN 2011-10-05 20:49:21+00:00   \n",
       "2            No Industry                    NaN 2011-10-18 17:31:26+00:00   \n",
       "3            No Industry                    NaN 2011-11-09 20:39:29+00:00   \n",
       "4            No Industry                    NaN 2011-12-10 22:14:44+00:00   \n",
       "\n",
       "   professionals_id_num                 tag_users_user_id  \\\n",
       "0                     0                               NaN   \n",
       "1                     1                               NaN   \n",
       "2                     2  0c673e046d824ec0ad0ebe012a0673e4   \n",
       "3                     3                               NaN   \n",
       "4                     4                               NaN   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  consulting,consulting,consulting,consulting,co...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  questions_tag_name  \\\n",
       "0                                  consulting,resume   \n",
       "1                                                NaN   \n",
       "2  bain,emotional,residency,entrepreneurship,scho...   \n",
       "3  police,law,fashion-design,law-enforcement,crim...   \n",
       "4                                                NaN   \n",
       "\n",
       "                               professional_all_tags  \\\n",
       "0                                  consulting,resume   \n",
       "1                                             No Tag   \n",
       "2  bain,emotional,residency,entrepreneurship,air-...   \n",
       "3  fashion-design,police,law,law-enforcement,crim...   \n",
       "4                                             No Tag   \n",
       "\n",
       "                               professional_features  \n",
       "0                          (0, [consulting, resume])  \n",
       "1                                      (1, [No Tag])  \n",
       "2  (2, [bain, emotional, residency, entrepreneurs...  \n",
       "3  (3, [fashion-design, police, law, law-enforcem...  \n",
       "4                                      (4, [No Tag])  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_professionals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightFM Dataset**: In this steps we are going to build lightfm datasets. And then we will be building our ineractions matrix, weights and professional/question features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   professor\n",
       "1                     lecture\n",
       "2                     college\n",
       "3                        army\n",
       "4                    military\n",
       "                 ...         \n",
       "77191         law-enforcement\n",
       "77192                    java\n",
       "77193        computer-science\n",
       "77194    computer-engineering\n",
       "77195             programming\n",
       "Length: 77196, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        consulting\n",
       "1                                            resume\n",
       "2                                            No Tag\n",
       "3                                              bain\n",
       "4                                         emotional\n",
       "                            ...                    \n",
       "228831                                    mentoring\n",
       "228832    indirect-sales-(channel)-and-direct-sales\n",
       "228833                          women-in-leadership\n",
       "228834                              contact-centers\n",
       "228835                               communications\n",
       "Length: 228836, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28152"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_professionals['professionals_id_num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23931"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_questions['questions_id_num']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_id_num</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>...</th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>id_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>num_of_ans_by_professional</th>\n",
       "      <th>num_ans_per_ques</th>\n",
       "      <th>num_tags_professional</th>\n",
       "      <th>num_tags_question</th>\n",
       "      <th>total_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>...</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>2016-07-31 15:35:54</td>\n",
       "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
       "      <td>2016-05-19 22:16:25+00:00</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>...</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-15 23:08:46</td>\n",
       "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
       "      <td>71</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-13 18:18:05</td>\n",
       "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
       "      <td>72</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>18373</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>computer-software</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3fc23809cda472780fc565334f35000</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>2018-08-14 10:37:01</td>\n",
       "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
       "      <td>102</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
       "      <td>2018-08-14 04:49:33+00:00</td>\n",
       "      <td>How should I prepare myself for my job search ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2410</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  f3519ab99a1a4a13a8a9ecb814287d2a  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  825f6e316a5f48328d6f8af831df9940  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  fb2c794175304c4caeb55e654270421f  a32736b04c27437da3078374d47af1b1   \n",
       "4  f3fc23809cda472780fc565334f35000  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                answers_question_id   answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  2016-04-29 19:40:14   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  2016-07-31 15:35:54   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  2018-04-15 23:08:46   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  2018-04-13 18:18:05   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  2018-08-14 10:37:01   \n",
       "\n",
       "                                        answers_body  answers_id_num  \\\n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...               0   \n",
       "1  <p>Hi Rodrigo!</p>\\n<p>The important thing to ...              11   \n",
       "2  <p>Congratulations on being interested in find...              71   \n",
       "3  <p>Hi Elisabeth! </p><p><br></p><p>If you are ...              72   \n",
       "4  <p>The most important thing that you can do is...             102   \n",
       "\n",
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  585ac233015447cc9e9a217044e515e1   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  5b751a8ee4a047f7a08ce9eb5e43e5a2   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-19 22:16:25+00:00   \n",
       "2 2018-04-12 17:13:45+00:00   \n",
       "3 2018-04-12 17:13:45+00:00   \n",
       "4 2018-08-14 04:49:33+00:00   \n",
       "\n",
       "                                     questions_title  ...  \\\n",
       "0                        Teacher   career   question  ...   \n",
       "1  what kind of  college could i go  to for a soc...  ...   \n",
       "2  What is the best way to prepare for studying e...  ...   \n",
       "3  What is the best way to prepare for studying e...  ...   \n",
       "4  How should I prepare myself for my job search ...  ...   \n",
       "\n",
       "  professionals_id_num                 tag_users_user_id  \\\n",
       "0                 2410  36ff3b3666df400f956f8335cf53e09e   \n",
       "1                 2410  36ff3b3666df400f956f8335cf53e09e   \n",
       "2                 2410  36ff3b3666df400f956f8335cf53e09e   \n",
       "3                18373  a32736b04c27437da3078374d47af1b1   \n",
       "4                 2410  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0  engineering,computer-science,science,college,e...   \n",
       "1  engineering,computer-science,science,college,e...   \n",
       "2  engineering,computer-science,science,college,e...   \n",
       "3                                  computer-software   \n",
       "4  engineering,computer-science,science,college,e...   \n",
       "\n",
       "                               id_y score_y  num_of_ans_by_professional  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54       1                        1710   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289       1                        1710   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba       2                        1710   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba       2                           1   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff       1                        1710   \n",
       "\n",
       "  num_ans_per_ques num_tags_professional num_tags_question  total_weights  \n",
       "0                1                  12.0               3.0            1.0  \n",
       "1                1                  12.0               3.0            1.0  \n",
       "2                2                  12.0               3.0            0.5  \n",
       "3                2                   1.0               3.0            0.5  \n",
       "4                1                  12.0               4.0            1.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50098"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    list(\n",
    "        zip(\n",
    "            df_merge['professionals_id_num'],\n",
    "            df_merge['questions_id_num'],\n",
    "            df_merge['total_weights']\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset building for lightFM\n",
    "\n",
    "# define our dataset variable\n",
    "# then we feed unique professionals and questions ids\n",
    "# and item and professional feature list\n",
    "# this will create lightfm internel mapping\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    set(df_professionals['professionals_id_num']),\n",
    "    set(df_questions['questions_id_num']),\n",
    "    item_features=question_feature_list,\n",
    "    user_features=professional_feature_list\n",
    ")\n",
    "\n",
    "# now we are building ineractions matrix between professionals and questions.\n",
    "# we are passing professional and question id as a tuple\n",
    "# e.g -> pd.Series ((pro_id, question_id), (pro_id, question_id))\n",
    "# then we use lightFM build in method for building interactions matrix\n",
    "df_merge['author_question_id_tuple'] = list(\n",
    "    zip(\n",
    "        df_merge['professionals_id_num'],\n",
    "        df_merge['questions_id_num'],\n",
    "        df_merge['total_weights']\n",
    "    )\n",
    ")\n",
    "\n",
    "interactions, weights = dataset.build_interactions(\n",
    "    df_merge['author_question_id_tuple']\n",
    ")\n",
    "\n",
    "# now we are building our questions and professionals features\n",
    "# in a way that lightFM understand.\n",
    "# we are using lightFM build in method for building\n",
    "# questions and professionals features\n",
    "questions_features = dataset.build_item_features(\n",
    "    df_questions['question_features']\n",
    ")\n",
    "\n",
    "professional_features = dataset.build_user_features(\n",
    "    df_professionals['professional_features']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model building and training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:16<00:00,  3.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x325ee2fd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building part\n",
    "\n",
    "# define lightFm model by specifying hyper-parameter\n",
    "# then fit the model with interactions matrix, item and user features\n",
    "model = LightFM(\n",
    "    no_components=150,\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    random_state=2019\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    interactions,\n",
    "    item_features=questions_features,\n",
    "    user_features=professional_features,\n",
    "    sample_weight=weights,\n",
    "    epochs=5,\n",
    "    num_threads=4,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the performance of the model \n",
    "Now we have to evaluate our model to see it's performance. No matter how good your model is, if you can't evaluate your model correctly you can't imporove and trust your model. For recommendation problem, there is not very good matrics for evaluating. But luckily lightfm provides us a very rich set of evaluating matrics. In this steps, we will be calculating AUC scores for our model.\n",
    "\n",
    "**What is AUC score in lightfm library?**: It measure the ROC AUC metric for a model: the probability that a randomly chosen positive example has a higher score than a randomly chosen negative example. A perfect score is 1.0. \n",
    "\n",
    "Let's see what is our model score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9149836"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auc_score(model, interactions, questions_features, professional_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That is really impresive. Over AUC is over 90 percent. That is really excellent. This tells us that the quality of our overall model is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make real recommendations**: Now we already see how our model is by looking at AUC score. But now let's see some real example of recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "\n",
    "def recommend_questions(professional_ids):\n",
    "    for professional in professional_ids:\n",
    "        # print their previous answered question title\n",
    "        previous_q_id_num = df_merge.loc[df_merge['professionals_id_num'] == professional][:3]['questions_id_num']\n",
    "        df_previous_questions = df_questions.loc[df_questions['questions_id_num'].isin(previous_q_id_num)]\n",
    "        print('Professional Id (' + str(professional) + \"): Previous Answered Questions\")\n",
    "        display_side_by_side(\n",
    "            df_previous_questions[['questions_title', 'question_features']],\n",
    "            df_professionals.loc[df_professionals.professionals_id_num == professional][['professionals_id_num','professionals_tag_name']])\n",
    "        \n",
    "        # predict\n",
    "        discard_qu_id = df_previous_questions['questions_id_num'].values.tolist()\n",
    "        df_use_for_prediction = df_questions.loc[~df_questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        questions_id_for_predict = df_use_for_prediction['questions_id_num'].values.tolist()\n",
    "        \n",
    "        scores = model.predict(\n",
    "            professional,\n",
    "            questions_id_for_predict,\n",
    "            item_features=questions_features,\n",
    "            user_features=professional_features)\n",
    "        \n",
    "        df_use_for_prediction['scores'] = scores\n",
    "        df_use_for_prediction = df_use_for_prediction.sort_values(by='scores', ascending=False)[:8]\n",
    "        print('Professional Id (' + str(professional) + \"): Recommended Questions: \")\n",
    "        display(df_use_for_prediction[['questions_title', 'question_features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (1200): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>marketing,strategy,entrepreneurship,management,java,advertising,python,data-analysis,online-advertising,real-estate,team-leadership,dj,analytics,display-advertising,football,blackjack,hip-hop,billiards,break</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (1200): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20217</th>\n",
       "      <td>What are the most common and uncommon battles ...</td>\n",
       "      <td>(20217, [entrepreneurship, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>Is it worth it to pursue an advanced degree in...</td>\n",
       "      <td>(17876, [marketing, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19011</th>\n",
       "      <td>How do you get started in starting your own bu...</td>\n",
       "      <td>(19011, [marketing, business, management])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>How do you become the youngest female CEO of a...</td>\n",
       "      <td>(10191, [entrepreneurship, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15671</th>\n",
       "      <td>How beneficial will a business major be ?</td>\n",
       "      <td>(15671, [finance, marketing, accountant, busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10073</th>\n",
       "      <td>How important is a business degree when trying...</td>\n",
       "      <td>(10073, [entrepreneurship, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20431</th>\n",
       "      <td>What are the average income for someone that w...</td>\n",
       "      <td>(20431, [entrepreneurship, business])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13378</th>\n",
       "      <td>As someone who one day wants to open up his ow...</td>\n",
       "      <td>(13378, [marketing, finance, sales, entreprene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "20217  What are the most common and uncommon battles ...   \n",
       "17876  Is it worth it to pursue an advanced degree in...   \n",
       "19011  How do you get started in starting your own bu...   \n",
       "10191  How do you become the youngest female CEO of a...   \n",
       "15671          How beneficial will a business major be ?   \n",
       "10073  How important is a business degree when trying...   \n",
       "20431  What are the average income for someone that w...   \n",
       "13378  As someone who one day wants to open up his ow...   \n",
       "\n",
       "                                       question_features  \n",
       "20217              (20217, [entrepreneurship, business])  \n",
       "17876                     (17876, [marketing, business])  \n",
       "19011         (19011, [marketing, business, management])  \n",
       "10191              (10191, [entrepreneurship, business])  \n",
       "15671  (15671, [finance, marketing, accountant, busin...  \n",
       "10073              (10073, [entrepreneurship, business])  \n",
       "20431              (20431, [entrepreneurship, business])  \n",
       "13378  (13378, [marketing, finance, sales, entreprene...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (19897): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22784</th>\n",
       "      <td>Do companies truly focus on your college major when applying for jobs?</td>\n",
       "      <td>(22784, [major])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19897</th>\n",
       "      <td>19897</td>\n",
       "      <td>illustration,graphic-design,adobe-creative-suite,comic-books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (19897): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>what is one of best things about being an anim...</td>\n",
       "      <td>(2310, [design, artist, animation, art])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9682</th>\n",
       "      <td>How to get started in animation?</td>\n",
       "      <td>(9682, [artist, animation, art])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19407</th>\n",
       "      <td>How can you be a successful photographer? What...</td>\n",
       "      <td>(19407, [art, graphic-design, photography])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>How should you start in the Graphic Design ind...</td>\n",
       "      <td>(6058, [design, graphic-design, art])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>Is Competition In The Animation Field Low or H...</td>\n",
       "      <td>(1416, [art, animation])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>What is a good app to use for animating?</td>\n",
       "      <td>(1203, [art, animation])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>what are the required fields forgraphic design?</td>\n",
       "      <td>(17325, [art, graphic-design])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>Would a Graphic Design degree be a feesible op...</td>\n",
       "      <td>(13484, [art, graphic-design])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "2310   what is one of best things about being an anim...   \n",
       "9682                    How to get started in animation?   \n",
       "19407  How can you be a successful photographer? What...   \n",
       "6058   How should you start in the Graphic Design ind...   \n",
       "1416   Is Competition In The Animation Field Low or H...   \n",
       "1203            What is a good app to use for animating?   \n",
       "17325    what are the required fields forgraphic design?   \n",
       "13484  Would a Graphic Design degree be a feesible op...   \n",
       "\n",
       "                                 question_features  \n",
       "2310      (2310, [design, artist, animation, art])  \n",
       "9682              (9682, [artist, animation, art])  \n",
       "19407  (19407, [art, graphic-design, photography])  \n",
       "6058         (6058, [design, graphic-design, art])  \n",
       "1416                      (1416, [art, animation])  \n",
       "1203                      (1203, [art, animation])  \n",
       "17325               (17325, [art, graphic-design])  \n",
       "13484               (13484, [art, graphic-design])  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (3): Previous Answered Questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11339</th>\n",
       "      <td>What are the different jobs a person can do in Forensic Science?</td>\n",
       "      <td>(11339, [criminal, science, forensic, justice])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>What does a typical work day for a forensic scientist look like?</td>\n",
       "      <td>(14818, [No Tag])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19077</th>\n",
       "      <td>Is most of your day spent working when being a detective?</td>\n",
       "      <td>(19077, [detective])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id_num</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (3): Recommended Questions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_title</th>\n",
       "      <th>question_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>How long does it take to become a Detective?</td>\n",
       "      <td>(2423, [police, law, law-enforcement, criminal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17184</th>\n",
       "      <td>What types of Detectives are there?</td>\n",
       "      <td>(17184, [police, law, law-enforcement, crimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>What are important characteristics of a lawyer?</td>\n",
       "      <td>(1941, [law-enforcement, law-school, law, lawy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18124</th>\n",
       "      <td>what is the starting salary for a police offic...</td>\n",
       "      <td>(18124, [law, law-enforcement])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>Do you go to college, then B.L.E.T( Basic Law ...</td>\n",
       "      <td>(16214, [police, law, law-enforcement])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>I want to be a police officer or a police disp...</td>\n",
       "      <td>(9778, [police, police-officer, law, law-enfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18947</th>\n",
       "      <td>Could I go straight into Law Enforcememt, when...</td>\n",
       "      <td>(18947, [police, law, law-enforcement])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20902</th>\n",
       "      <td>How would i get into a law school?</td>\n",
       "      <td>(20902, [law, law-enforcement])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         questions_title  \\\n",
       "2423        How long does it take to become a Detective?   \n",
       "17184                What types of Detectives are there?   \n",
       "1941     What are important characteristics of a lawyer?   \n",
       "18124  what is the starting salary for a police offic...   \n",
       "16214  Do you go to college, then B.L.E.T( Basic Law ...   \n",
       "9778   I want to be a police officer or a police disp...   \n",
       "18947  Could I go straight into Law Enforcememt, when...   \n",
       "20902                 How would i get into a law school?   \n",
       "\n",
       "                                       question_features  \n",
       "2423   (2423, [police, law, law-enforcement, criminal...  \n",
       "17184  (17184, [police, law, law-enforcement, crimina...  \n",
       "1941   (1941, [law-enforcement, law-school, law, lawy...  \n",
       "18124                    (18124, [law, law-enforcement])  \n",
       "16214            (16214, [police, law, law-enforcement])  \n",
       "9778   (9778, [police, police-officer, law, law-enfor...  \n",
       "18947            (18947, [police, law, law-enforcement])  \n",
       "20902                    (20902, [law, law-enforcement])  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommend_questions([1200, 19897, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: Awesome! Finally we can see our recommendation by our model. Let's take some time to ponder over the recommendations.\n",
    "\n",
    "* For the first professional(1200) has not answer any questions yet. But he/she follows some tags. Our model take those tags as features and predict questions that has similar tags.\n",
    "* For the second professionals(19897) answered one questions that has tag major. But in his profile he follows tags like creative works like arts, illurstrator etc. So our model recommend questions that has creative tags like arts, illustrator because he follows more tags one creative works.\n",
    "* For the third professionals(3): answered questions that has tag forensic, criminal, science, justice, detective. From the tags we can get an idea of professionals interests. Our model also learn that. That's why it recommend items that has tags like law, criminal, detective.\n",
    "\n",
    "This is just a simple exploration. Hope you get idea of the model recommendations. The model can survive cold-start, high-popularity problem. It also recommend those questions that has less answer because of its weights that I provied during traning. Now we build our model and tested it. In the next section, we will look how we can put this model in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in Production\n",
    "We previously saw how lightfm model works and build for this project. Well, now we are going build a pipeline that will help us for putting this model into production. We are going to build class for each steps discuss in step 2. Also, we are going to build some additional functions and methods that will add additional functionality to the model. \n",
    "\n",
    "Here is the picture of our pipeline: \n",
    "![](https://i.imgur.com/Kh4rVcL.png)\n",
    "\n",
    "\n",
    "We will now build class for each of these steps. Without further do let's begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all our datasets again\n",
    "# and store them in pandas dataframe objects.\n",
    "base_path = './input/'\n",
    "df_answer_scores = pd.read_csv(\n",
    "    base_path + 'answer_scores.csv')\n",
    "\n",
    "df_answers = pd.read_csv(\n",
    "    base_path + 'answers.csv',\n",
    "    parse_dates=['answers_date_added'])\n",
    "\n",
    "df_comments = pd.read_csv(\n",
    "    base_path + 'comments.csv')\n",
    "\n",
    "df_emails = pd.read_csv(\n",
    "    base_path + 'emails.csv')\n",
    "\n",
    "df_group_memberships = pd.read_csv(\n",
    "    base_path + 'group_memberships.csv')\n",
    "\n",
    "df_groups = pd.read_csv(\n",
    "    base_path + 'groups.csv')\n",
    "\n",
    "df_matches = pd.read_csv(\n",
    "    base_path + 'matches.csv')\n",
    "\n",
    "df_professionals = pd.read_csv(\n",
    "    base_path + 'professionals.csv',\n",
    "    parse_dates=['professionals_date_joined'])\n",
    "\n",
    "df_question_scores = pd.read_csv(\n",
    "    base_path + 'question_scores.csv')\n",
    "\n",
    "df_questions = pd.read_csv(\n",
    "    base_path + 'questions.csv',\n",
    "    parse_dates=['questions_date_added'])\n",
    "\n",
    "df_school_memberships = pd.read_csv(\n",
    "    base_path + 'school_memberships.csv')\n",
    "\n",
    "df_students = pd.read_csv(\n",
    "    base_path + 'students.csv',\n",
    "    parse_dates=['students_date_joined'])\n",
    "\n",
    "df_tag_questions = pd.read_csv(\n",
    "    base_path + 'tag_questions.csv')\n",
    "\n",
    "df_tag_users = pd.read_csv(\n",
    "    base_path + 'tag_users.csv')\n",
    "\n",
    "df_tags = pd.read_csv(\n",
    "    base_path + 'tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Processing Class**: Now we are going to build a class that will be used for data cleaning and processing specificly designed for CareerVillage Datasetes. I have provided details document and comment with each part of the code. This will help understanding the code and intention very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CareerVillageDataPreparation:\n",
    "    \"\"\"\n",
    "    Clean and process data CareerVillage Data. \n",
    "    \n",
    "    This class process data in a way that will be useful\n",
    "    for building lightFM dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _assign_unique_id(self, data, id_col_name):\n",
    "        \"\"\"\n",
    "        Generate unique integer id for users, questions and answers\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: Dataframe\n",
    "            Pandas Dataframe for Users or Q&A. \n",
    "        id_col_name : String \n",
    "            New integer id's column name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dataframe\n",
    "            Updated dataframe containing new id column\n",
    "        \"\"\"\n",
    "        new_dataframe=data.assign(\n",
    "            int_id_col_name=np.arange(len(data))\n",
    "            ).reset_index(drop=True)\n",
    "        return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "    def _dropna(self, data, column, axis):\n",
    "        \"\"\"Drop null values from specific column\"\"\"\n",
    "        return data.dropna(column, axis=axis)\n",
    "\n",
    "    def _merge_data(self, left_data, left_key, right_data, right_key, how):\n",
    "        \"\"\"\n",
    "        This function is used for merging two dataframe.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        left_data: Dataframe\n",
    "            Left side dataframe for merge\n",
    "        left_key: String\n",
    "            Left Dataframe merge key\n",
    "        right_data: Dataframe\n",
    "            Right side dataframe for merge\n",
    "        right_key: String\n",
    "            Right Dataframe merge key\n",
    "        how: String\n",
    "            Method of merge (inner, left, right, outer)\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        Dataframe\n",
    "            A new dataframe merging left and right dataframe\n",
    "        \"\"\"\n",
    "        return left_data.merge(\n",
    "            right_data,\n",
    "            how=how,\n",
    "            left_on=left_key,\n",
    "            right_on=right_key)\n",
    "\n",
    "    def _group_tags(self, data, group_by, tag_column):\n",
    "        \"\"\"Grouop multiple tags into single rows sepearated by comma\"\"\"\n",
    "        return data.groupby(\n",
    "            [group_by])[tag_column].apply(\n",
    "            ','.join).reset_index()\n",
    "\n",
    "    def _merge_cv_datasets(\n",
    "        self,\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,tag_users, questions_score):\n",
    "        \"\"\"\n",
    "        This function merges all the necessary \n",
    "        CareerVillage dataset in defined way. \n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,\n",
    "        tag_users,\n",
    "        questions_score: Dataframe\n",
    "            Pandas dataframe defined by it's name\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        questions, professionals: Dataframe\n",
    "            Updated dataframe after merge\n",
    "        merge: Dataframe\n",
    "            A new datframe after merging answers with questions\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # merge tag_questions with tags name\n",
    "        # then group all tags for each question into single rows\n",
    "        tag_question = self._merge_data(\n",
    "            left_data=tag_questions,\n",
    "            left_key='tag_questions_tag_id',\n",
    "            right_data=tags,\n",
    "            right_key='tags_tag_id',\n",
    "            how='inner')\n",
    "        tag_question = self._group_tags(\n",
    "            data=tag_question,\n",
    "            group_by='tag_questions_question_id',\n",
    "            tag_column='tags_tag_name')\n",
    "        \n",
    "        tag_question = tag_question.rename(\n",
    "            columns={'tags_tag_name': 'questions_tag_name'})\n",
    "        \n",
    "        # merge tag_users with tags name\n",
    "        # then group all tags for each user into single rows \n",
    "        # after that rename the tag column name\n",
    "        tags_pro = self._merge_data(\n",
    "            left_data=tag_users,\n",
    "            left_key='tag_users_tag_id',\n",
    "            right_data=tags,\n",
    "            right_key='tags_tag_id',\n",
    "            how='inner')\n",
    "        tags_pro = self._group_tags(\n",
    "            data=tags_pro,\n",
    "            group_by='tag_users_user_id',\n",
    "            tag_column='tags_tag_name')\n",
    "        tags_pro = tags_pro.rename(\n",
    "            columns={'tags_tag_name': 'professionals_tag_name'})\n",
    "        \n",
    "        # merge professionals and questions tags with main merge_dataset \n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_id',\n",
    "            right_data=tag_question,\n",
    "            right_key='tag_questions_question_id',\n",
    "            how='left')\n",
    "        professionals = self._merge_data(\n",
    "            left_data=professionals,\n",
    "            left_key='professionals_id',\n",
    "            right_data=tags_pro,\n",
    "            right_key='tag_users_user_id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge questions with scores \n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_id',\n",
    "            right_data=questions_score,\n",
    "            right_key='id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge questions with students\n",
    "        questions = self._merge_data(\n",
    "            left_data=questions,\n",
    "            left_key='questions_author_id',\n",
    "            right_data=students,\n",
    "            right_key='students_id',\n",
    "            how='left')\n",
    "        \n",
    "        # merge answers with questions\n",
    "        # then merge professionals and questions score with that\n",
    "        merge = self._merge_data(\n",
    "            left_data=answers,\n",
    "            left_key='answers_question_id',\n",
    "            right_data=questions,\n",
    "            right_key='questions_id',\n",
    "            how='inner')\n",
    "        \n",
    "        merge = self._merge_data(\n",
    "            left_data=merge,\n",
    "            left_key='answers_author_id',\n",
    "            right_data=professionals,\n",
    "            right_key='professionals_id',\n",
    "            how='inner')\n",
    "        return questions, professionals, merge\n",
    "\n",
    "    def _drop_duplicates_tags(self, data, col_name):\n",
    "        # drop duplicates tags from each row\n",
    "        return (\n",
    "            data[col_name].str.split(\n",
    "                ',').apply(set).str.join(','))\n",
    "\n",
    "    def _merge_pro_pre_ans_tags(self, professionals, merge):\n",
    "        ########################\n",
    "        # Merge professionals previous answered\n",
    "        # questions tags into professionals tags\n",
    "        ########################\n",
    "        \n",
    "        # select professionals answered questions tags\n",
    "        # and stored as a dataframe\n",
    "        professionals_prev_ans_tags = (\n",
    "            merge[['professionals_id', 'questions_tag_name']])\n",
    "        # drop null values from that\n",
    "        professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
    "        \n",
    "        # because professsionals answers multiple questions,\n",
    "        # we group all of tags of each user into single row\n",
    "        professionals_prev_ans_tags = self._group_tags(\n",
    "            data=professionals_prev_ans_tags,\n",
    "            group_by='professionals_id',\n",
    "            tag_column='questions_tag_name')\n",
    "        \n",
    "        # drop duplicates tags from each professionals rows\n",
    "        professionals_prev_ans_tags['questions_tag_name'] = \\\n",
    "        self._drop_duplicates_tags(\n",
    "            professionals_prev_ans_tags, 'questions_tag_name')\n",
    "        \n",
    "        # finally merge the dataframe with professionals dataframe\n",
    "        professionals = self._merge_data(\n",
    "            left_data=professionals,\n",
    "            left_key='professionals_id',\n",
    "            right_data=professionals_prev_ans_tags,\n",
    "            right_key='professionals_id',\n",
    "            how='left')\n",
    "        \n",
    "        # join professionals tags and their answered tags \n",
    "        # we replace nan values with \"\"\n",
    "        professionals['professional_all_tags'] = (\n",
    "            professionals[['professionals_tag_name',\n",
    "                           'questions_tag_name']].apply(\n",
    "                lambda x: ','.join(x.dropna()),\n",
    "                axis=1))\n",
    "        return professionals\n",
    "\n",
    "    def prepare(\n",
    "        self,\n",
    "        professionals,students,\n",
    "        questions,answers,\n",
    "        tags,tag_questions,tag_users, questions_score):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function clean and process \n",
    "        CareerVillage Data sets. \n",
    "        \"\"\"\n",
    "        \n",
    "        # assign unique integer id\n",
    "        professionals = self._assign_unique_id(\n",
    "            professionals, 'professionals_id_num')\n",
    "        students = self._assign_unique_id(\n",
    "            students, 'students_id_num')\n",
    "        questions = self._assign_unique_id(\n",
    "            questions, 'questions_id_num')\n",
    "        answers = self._assign_unique_id(\n",
    "            answers, 'answers_id_num')\n",
    "        \n",
    "        # just dropna from tags \n",
    "        tags = tags.dropna()\n",
    "        tags['tags_tag_name'] = tags['tags_tag_name'].str.replace(\n",
    "            '#', '')\n",
    "        \n",
    "        # merge necessary datasets\n",
    "        df_questions, df_professionals, df_merge = self._merge_cv_datasets(\n",
    "            professionals,students,\n",
    "            questions,answers,\n",
    "            tags,tag_questions,tag_users,\n",
    "            questions_score)\n",
    "        \n",
    "        # Generate some features for calculates weights\n",
    "        # that will use with interaction matrix\n",
    "        df_merge['num_ans_per_ques'] = df_merge.groupby(\n",
    "            ['questions_id'])['answers_id'].transform('count')\n",
    "        \n",
    "        # merge pro previoius answered question tags with pro tags \n",
    "        df_professionals = self._merge_pro_pre_ans_tags(\n",
    "            df_professionals, df_merge)\n",
    "        \n",
    "        # some more pre-processing \n",
    "        # handling null values \n",
    "        df_questions['score'] = df_questions['score'].fillna(0)\n",
    "        df_questions['score'] = df_questions['score'].astype(int)\n",
    "        df_questions['questions_tag_name'] = \\\n",
    "        df_questions['questions_tag_name'].fillna('No Tag')\n",
    "        \n",
    "        # remove duplicates tags from each questions \n",
    "        df_questions['questions_tag_name'] = \\\n",
    "        df_questions['questions_tag_name'].str.split(\n",
    "            ',').apply(set).str.join(',')\n",
    "\n",
    "        # fill nan with 'No Tag' if any \n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].fillna(\n",
    "            'No Tag')\n",
    "        # replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].replace(\n",
    "            '', 'No Tag')\n",
    "        \n",
    "        df_professionals['professionals_location'] = \\\n",
    "        df_professionals['professionals_location'].fillna(\n",
    "            'No Location')\n",
    "        \n",
    "        df_professionals['professionals_industry'] = \\\n",
    "        df_professionals['professionals_industry'].fillna(\n",
    "            'No Industry')\n",
    "\n",
    "        # remove duplicates tags from each professionals\n",
    "        df_professionals['professional_all_tags'] = \\\n",
    "        df_professionals['professional_all_tags'].str.split(\n",
    "            ',').apply(set).str.join(',')\n",
    "\n",
    "        # remove some null values from df_merge\n",
    "        df_merge['num_ans_per_ques']  = \\\n",
    "        df_merge['num_ans_per_ques'].fillna(0)\n",
    "        \n",
    "        return df_questions, df_professionals, df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_id_num</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>id_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>num_of_ans_by_professional</th>\n",
       "      <th>num_ans_per_ques</th>\n",
       "      <th>num_tags_professional</th>\n",
       "      <th>num_tags_question</th>\n",
       "      <th>total_weights</th>\n",
       "      <th>author_question_id_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>2016-07-31 15:35:54</td>\n",
       "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
       "      <td>2016-05-19 22:16:25+00:00</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 7, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-15 23:08:46</td>\n",
       "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
       "      <td>71</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2410, 33, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-13 18:18:05</td>\n",
       "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
       "      <td>72</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>computer-software</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(18373, 33, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3fc23809cda472780fc565334f35000</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>2018-08-14 10:37:01</td>\n",
       "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
       "      <td>102</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
       "      <td>2018-08-14 04:49:33+00:00</td>\n",
       "      <td>How should I prepare myself for my job search ...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 47, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  f3519ab99a1a4a13a8a9ecb814287d2a  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  825f6e316a5f48328d6f8af831df9940  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  fb2c794175304c4caeb55e654270421f  a32736b04c27437da3078374d47af1b1   \n",
       "4  f3fc23809cda472780fc565334f35000  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                answers_question_id   answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  2016-04-29 19:40:14   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  2016-07-31 15:35:54   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  2018-04-15 23:08:46   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  2018-04-13 18:18:05   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  2018-08-14 10:37:01   \n",
       "\n",
       "                                        answers_body  answers_id_num  \\\n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...               0   \n",
       "1  <p>Hi Rodrigo!</p>\\n<p>The important thing to ...              11   \n",
       "2  <p>Congratulations on being interested in find...              71   \n",
       "3  <p>Hi Elisabeth! </p><p><br></p><p>If you are ...              72   \n",
       "4  <p>The most important thing that you can do is...             102   \n",
       "\n",
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  585ac233015447cc9e9a217044e515e1   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  5b751a8ee4a047f7a08ce9eb5e43e5a2   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-19 22:16:25+00:00   \n",
       "2 2018-04-12 17:13:45+00:00   \n",
       "3 2018-04-12 17:13:45+00:00   \n",
       "4 2018-08-14 04:49:33+00:00   \n",
       "\n",
       "                                     questions_title  ...  \\\n",
       "0                        Teacher   career   question  ...   \n",
       "1  what kind of  college could i go  to for a soc...  ...   \n",
       "2  What is the best way to prepare for studying e...  ...   \n",
       "3  What is the best way to prepare for studying e...  ...   \n",
       "4  How should I prepare myself for my job search ...  ...   \n",
       "\n",
       "                  tag_users_user_id  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  a32736b04c27437da3078374d47af1b1   \n",
       "4  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0  engineering,computer-science,science,college,e...   \n",
       "1  engineering,computer-science,science,college,e...   \n",
       "2  engineering,computer-science,science,college,e...   \n",
       "3                                  computer-software   \n",
       "4  engineering,computer-science,science,college,e...   \n",
       "\n",
       "                               id_y score_y num_of_ans_by_professional  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54       1                       1710   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289       1                       1710   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba       2                       1710   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba       2                          1   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff       1                       1710   \n",
       "\n",
       "   num_ans_per_ques num_tags_professional num_tags_question total_weights  \\\n",
       "0                 1                  12.0               3.0           1.0   \n",
       "1                 1                  12.0               3.0           1.0   \n",
       "2                 2                  12.0               3.0           0.5   \n",
       "3                 2                   1.0               3.0           0.5   \n",
       "4                 1                  12.0               4.0           1.0   \n",
       "\n",
       "   author_question_id_tuple  \n",
       "0            (2410, 0, 1.0)  \n",
       "1            (2410, 7, 1.0)  \n",
       "2           (2410, 33, 0.5)  \n",
       "3          (18373, 33, 0.5)  \n",
       "4           (2410, 47, 1.0)  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge['questions_date_added'] = pd.to_datetime(df_merge['questions_date_added']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_merge['students_date_joined'] = pd.to_datetime(df_merge['students_date_joined']).dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_question_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_id_num</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_users_user_id</th>\n",
       "      <th>professionals_tag_name</th>\n",
       "      <th>id_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>num_of_ans_by_professional</th>\n",
       "      <th>num_ans_per_ques</th>\n",
       "      <th>num_tags_professional</th>\n",
       "      <th>num_tags_question</th>\n",
       "      <th>total_weights</th>\n",
       "      <th>author_question_id_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>2016-04-29 19:40:14</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>2016-07-31 15:35:54</td>\n",
       "      <td>&lt;p&gt;Hi Rodrigo!&lt;/p&gt;\\n&lt;p&gt;The important thing to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>585ac233015447cc9e9a217044e515e1</td>\n",
       "      <td>2016-05-19 22:16:25+00:00</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 7, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825f6e316a5f48328d6f8af831df9940</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-15 23:08:46</td>\n",
       "      <td>&lt;p&gt;Congratulations on being interested in find...</td>\n",
       "      <td>71</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2410, 33, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb2c794175304c4caeb55e654270421f</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2018-04-13 18:18:05</td>\n",
       "      <td>&lt;p&gt;Hi Elisabeth! &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;If you are ...</td>\n",
       "      <td>72</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>34217a1861d640a58c85e033414cf9cb</td>\n",
       "      <td>2018-04-12 17:13:45+00:00</td>\n",
       "      <td>What is the best way to prepare for studying e...</td>\n",
       "      <td>...</td>\n",
       "      <td>a32736b04c27437da3078374d47af1b1</td>\n",
       "      <td>computer-software</td>\n",
       "      <td>0149c6d63e214040b44d4a3789bb00ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(18373, 33, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3fc23809cda472780fc565334f35000</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>2018-08-14 10:37:01</td>\n",
       "      <td>&lt;p&gt;The most important thing that you can do is...</td>\n",
       "      <td>102</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>5b751a8ee4a047f7a08ce9eb5e43e5a2</td>\n",
       "      <td>2018-08-14 04:49:33+00:00</td>\n",
       "      <td>How should I prepare myself for my job search ...</td>\n",
       "      <td>...</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>engineering,computer-science,science,college,e...</td>\n",
       "      <td>acc611cfb5c44daa8a3d7d65dfffa5ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2410, 47, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                 answers_author_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  f3519ab99a1a4a13a8a9ecb814287d2a  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  825f6e316a5f48328d6f8af831df9940  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  fb2c794175304c4caeb55e654270421f  a32736b04c27437da3078374d47af1b1   \n",
       "4  f3fc23809cda472780fc565334f35000  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                answers_question_id   answers_date_added  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  2016-04-29 19:40:14   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  2016-07-31 15:35:54   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  2018-04-15 23:08:46   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  2018-04-13 18:18:05   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  2018-08-14 10:37:01   \n",
       "\n",
       "                                        answers_body  answers_id_num  \\\n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...               0   \n",
       "1  <p>Hi Rodrigo!</p>\\n<p>The important thing to ...              11   \n",
       "2  <p>Congratulations on being interested in find...              71   \n",
       "3  <p>Hi Elisabeth! </p><p><br></p><p>If you are ...              72   \n",
       "4  <p>The most important thing that you can do is...             102   \n",
       "\n",
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289  585ac233015447cc9e9a217044e515e1   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba  34217a1861d640a58c85e033414cf9cb   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff  5b751a8ee4a047f7a08ce9eb5e43e5a2   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-19 22:16:25+00:00   \n",
       "2 2018-04-12 17:13:45+00:00   \n",
       "3 2018-04-12 17:13:45+00:00   \n",
       "4 2018-08-14 04:49:33+00:00   \n",
       "\n",
       "                                     questions_title  ...  \\\n",
       "0                        Teacher   career   question  ...   \n",
       "1  what kind of  college could i go  to for a soc...  ...   \n",
       "2  What is the best way to prepare for studying e...  ...   \n",
       "3  What is the best way to prepare for studying e...  ...   \n",
       "4  How should I prepare myself for my job search ...  ...   \n",
       "\n",
       "                  tag_users_user_id  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e   \n",
       "1  36ff3b3666df400f956f8335cf53e09e   \n",
       "2  36ff3b3666df400f956f8335cf53e09e   \n",
       "3  a32736b04c27437da3078374d47af1b1   \n",
       "4  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                              professionals_tag_name  \\\n",
       "0  engineering,computer-science,science,college,e...   \n",
       "1  engineering,computer-science,science,college,e...   \n",
       "2  engineering,computer-science,science,college,e...   \n",
       "3                                  computer-software   \n",
       "4  engineering,computer-science,science,college,e...   \n",
       "\n",
       "                               id_y score_y num_of_ans_by_professional  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54       1                       1710   \n",
       "1  0f1d6a4f276c4a05878dd48e03e52289       1                       1710   \n",
       "2  0149c6d63e214040b44d4a3789bb00ba       2                       1710   \n",
       "3  0149c6d63e214040b44d4a3789bb00ba       2                          1   \n",
       "4  acc611cfb5c44daa8a3d7d65dfffa5ff       1                       1710   \n",
       "\n",
       "   num_ans_per_ques num_tags_professional num_tags_question total_weights  \\\n",
       "0                 1                  12.0               3.0           1.0   \n",
       "1                 1                  12.0               3.0           1.0   \n",
       "2                 2                  12.0               3.0           0.5   \n",
       "3                 2                   1.0               3.0           0.5   \n",
       "4                 1                  12.0               4.0           1.0   \n",
       "\n",
       "   author_question_id_tuple  \n",
       "0            (2410, 0, 1.0)  \n",
       "1            (2410, 7, 1.0)  \n",
       "2           (2410, 33, 0.5)  \n",
       "3          (18373, 33, 0.5)  \n",
       "4           (2410, 47, 1.0)  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Data for LightFM Class**: From step 2 we already know that lightfm library except data in a very specific and elligent way. LightFM data format is already discussed in step 2. Feel free to read that. Now we are building a class that will be put all of dataset building puzzle in a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMDataPrep:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def create_features(self, dataframe, features_name, id_col_name):\n",
    "        \"\"\"\n",
    "        Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: Dataframe\n",
    "            Pandas Dataframe which contains features\n",
    "        features_name : List\n",
    "            List of feature columns name avaiable in dataframe\n",
    "        id_col_name: String\n",
    "            Column name which contains id of the question or\n",
    "            answer that the features will map to.\n",
    "            There are two possible values for this variable.\n",
    "            1. questions_id_num\n",
    "            2. professionals_id_num\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Pandas Series\n",
    "            A pandas series containing process features\n",
    "            that are ready for feed into lightfm.\n",
    "            The format of each value\n",
    "            will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "            Ex. -> (1, ['military', 'army', '5'])\n",
    "        \"\"\"\n",
    "\n",
    "        features = dataframe[features_name].apply(\n",
    "            lambda x: ','.join(x.map(str)), axis=1)\n",
    "        features = features.str.split(',')\n",
    "        features = list(zip(dataframe[id_col_name], features))\n",
    "        return features\n",
    "\n",
    "    def generate_feature_list(self, dataframe, features_name):\n",
    "        \"\"\"\n",
    "        Generate features list for mapping \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: Dataframe\n",
    "            Pandas Dataframe for Users or Q&A. \n",
    "        features_name : List\n",
    "            List of feature columns name avaiable in dataframe. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of all features for mapping \n",
    "        \"\"\"\n",
    "        features = dataframe[features_name].apply(\n",
    "            lambda x: ','.join(x.map(str)), axis=1)\n",
    "        features = features.str.split(',')\n",
    "        features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "        return features\n",
    "    \n",
    "    def create_data(self, questions, professionals, merge):\n",
    "        question_feature_list = self.generate_feature_list(\n",
    "            questions,\n",
    "            ['questions_tag_name'])\n",
    "\n",
    "        professional_feature_list = self.generate_feature_list(\n",
    "            professionals,\n",
    "            ['professional_all_tags'])\n",
    "        \n",
    "        merge['total_weights'] = 1 / (\n",
    "            merge['num_ans_per_ques'])\n",
    "        \n",
    "        # creating features for feeding into lightfm \n",
    "        questions['question_features'] = self.create_features(\n",
    "            questions, ['questions_tag_name'], \n",
    "            'questions_id_num')\n",
    "\n",
    "        professionals['professional_features'] = self.create_features(\n",
    "            professionals,\n",
    "            ['professional_all_tags'],\n",
    "            'professionals_id_num')\n",
    "        \n",
    "        return question_feature_list,\\\n",
    "    professional_feature_list,merge,questions,professionals\n",
    "        \n",
    "    def fit(self, questions, professionals, merge):\n",
    "        ########################\n",
    "        # Dataset building for lightfm\n",
    "        ########################\n",
    "        question_feature_list, \\\n",
    "        professional_feature_list,\\\n",
    "        merge,questions,professionals = \\\n",
    "        self.create_data(questions, professionals, merge)\n",
    "        \n",
    "        # define our dataset variable\n",
    "        # then we feed unique professionals and questions ids\n",
    "        # and item and professional feature list\n",
    "        # this will create lightfm internel mapping\n",
    "        dataset = Dataset()\n",
    "        dataset.fit(\n",
    "            set(professionals['professionals_id_num']), \n",
    "            set(questions['questions_id_num']),\n",
    "            item_features=question_feature_list, \n",
    "            user_features=professional_feature_list)\n",
    "\n",
    "        # now we are building interactions\n",
    "        # matrix between professionals and quesitons\n",
    "        # we are passing professional and questions id as a tuple\n",
    "        # e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
    "        # then we use lightfm build in method for building interactions matrix\n",
    "        merge['author_question_id_tuple'] = list(zip(\n",
    "            merge.professionals_id_num,\n",
    "            merge.questions_id_num,\n",
    "            merge.total_weights))\n",
    "\n",
    "        interactions, weights = dataset.build_interactions(\n",
    "            merge['author_question_id_tuple'])\n",
    "\n",
    "        # now we are building our questions and\n",
    "        # professionals features\n",
    "        # in a way that lightfm understand.\n",
    "        # we are using lightfm build in method for building\n",
    "        # questions and professionals features \n",
    "        questions_features = dataset.build_item_features(\n",
    "            questions['question_features'])\n",
    "\n",
    "        professional_features = dataset.build_user_features(\n",
    "            professionals['professional_features'])\n",
    "        \n",
    "        return interactions, weights, questions_features, professional_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model Class**: In step 2, we saw how we build and train our model. Now we are going to put those all together in TrainLightFM class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLightFM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def train_test_split(self, interactions, weights):\n",
    "        train_interactions, test_interactions = \\\n",
    "        cross_validation.random_train_test_split(\n",
    "            interactions, \n",
    "            random_state=np.random.RandomState(2019))\n",
    "        \n",
    "        train_weights, test_weights = \\\n",
    "        cross_validation.random_train_test_split(\n",
    "            weights, \n",
    "            random_state=np.random.RandomState(2019))\n",
    "        return train_interactions,\\\n",
    "    test_interactions, train_weights, test_weights\n",
    "    \n",
    "    def fit(self, interactions, weights,\n",
    "            questions_features, professional_features,\n",
    "            cross_validation=False,no_components=150,\n",
    "            learning_rate=0.05,\n",
    "            loss='warp',\n",
    "            random_state=2019,\n",
    "            verbose=True,\n",
    "            num_threads=4, epochs=5):\n",
    "\n",
    "        # Model building part\n",
    "        # define lightfm model by specifying hyper-parametre\n",
    "        # then fit the model with ineteractions matrix,\n",
    "        # item and user features\n",
    "        \n",
    "        model = LightFM(\n",
    "            no_components,\n",
    "            learning_rate,\n",
    "            loss=loss,\n",
    "            random_state=random_state)\n",
    "        model.fit(\n",
    "            interactions,\n",
    "            item_features=questions_features,\n",
    "            user_features=professional_features, sample_weight=weights,\n",
    "            epochs=epochs, num_threads=num_threads, verbose=verbose)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations classs**: Now we are going to build a class for making recommendations. This will make easy for making recommendations in djono api. This recommendations class build with extra features. You can use this for general prediction by giving professionals ids and questions features. It has another features that let's choose questions from range of two dates and make recommendation from those questions. \n",
    "\n",
    "This is useful because those professionals that choose email frequency lavel as \"weekly\" or \"daily\", we can select questions from a week and then recommend those questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMRecommendations:\n",
    "    \"\"\"\n",
    "    Make prediction given model and professional ids\n",
    "    \"\"\"\n",
    "    def __init__(self, lightfm_model,\n",
    "                 professionals_features,\n",
    "                 questions_features,\n",
    "                 questions,\n",
    "                 professionals,merge):\n",
    "        self.model = lightfm_model\n",
    "        self.professionals_features = professionals_features\n",
    "        self.questions_features = questions_features\n",
    "        self.questions = questions\n",
    "        self.professionals = professionals\n",
    "        self.merge = merge\n",
    "        \n",
    "    def previous_answered_questions(self, professionals_id):\n",
    "        previous_q_id_num = (\n",
    "            self.merge.loc[\\\n",
    "                self.merge['professionals_id_num'] == \\\n",
    "                professionals_id]['questions_id_num'])\n",
    "        \n",
    "        previous_answered_questions = self.questions.loc[\\\n",
    "            self.questions['questions_id_num'].isin(\n",
    "            previous_q_id_num)]\n",
    "        \n",
    "        return previous_answered_questions\n",
    "        \n",
    "    def _filter_question_by_pro(self, professionals_id):\n",
    "        \"\"\"Drop questions that professional already answer\"\"\"\n",
    "        previous_answered_questions = \\\n",
    "        self.previous_answered_questions(professionals_id)\n",
    "        \n",
    "        discard_qu_id = \\\n",
    "        previous_answered_questions['questions_id_num'].values.tolist()\n",
    "        \n",
    "        questions_for_prediction = \\\n",
    "        self.questions.loc[~self.questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        \n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def _filter_question_by_date(self, questions, start_date, end_date):\n",
    "        mask = \\\n",
    "        (questions['questions_date_added'] > start_date) & \\\n",
    "        (questions['questions_date_added'] <= end_date)\n",
    "        \n",
    "        return questions.loc[mask]\n",
    "        \n",
    "    def recommend_by_pro_id_general(self,\n",
    "                                    professional_id,\n",
    "                                    num_prediction=8):\n",
    "        questions_for_prediction = self._filter_question_by_pro(professional_id)\n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        \n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def recommend_by_pro_id_frequency_date_range(self,\n",
    "                                                 professional_id,\n",
    "                                                 start_date,\n",
    "                                                 end_date,\n",
    "                                                 num_prediction=8):\n",
    "        questions_for_prediction = \\\n",
    "        self._filter_question_by_pro(professional_id)\n",
    "        \n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        questions_for_prediction = self._filter_question_by_date(\n",
    "            questions_for_prediction, start_date, end_date)\n",
    "        \n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        return questions_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modified Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMRecommendations:\n",
    "    \"\"\"\n",
    "    Make prediction given model and professional ids\n",
    "    \"\"\"\n",
    "    def __init__(self, lightfm_model,\n",
    "                 professionals_features,\n",
    "                 questions_features,\n",
    "                 questions,\n",
    "                 professionals, merge):\n",
    "        self.model = lightfm_model\n",
    "        self.professionals_features = professionals_features\n",
    "        self.questions_features = questions_features\n",
    "        self.questions = questions.copy()\n",
    "        self.questions['questions_date_added'] = pd.to_datetime(self.questions['questions_date_added'])\n",
    "        self.professionals = professionals\n",
    "        self.merge = merge\n",
    "        \n",
    "    def previous_answered_questions(self, professionals_id):\n",
    "        previous_q_id_num = (\n",
    "            self.merge.loc[\\\n",
    "                self.merge['professionals_id_num'] == \\\n",
    "                professionals_id]['questions_id_num'])\n",
    "        \n",
    "        previous_answered_questions = self.questions.loc[\\\n",
    "            self.questions['questions_id_num'].isin(\n",
    "            previous_q_id_num)]\n",
    "        \n",
    "        return previous_answered_questions\n",
    "        \n",
    "    def _filter_question_by_pro(self, professionals_id):\n",
    "        \"\"\"Drop questions that professional already answer\"\"\"\n",
    "        previous_answered_questions = \\\n",
    "        self.previous_answered_questions(professionals_id)\n",
    "        \n",
    "        discard_qu_id = \\\n",
    "        previous_answered_questions['questions_id_num'].values.tolist()\n",
    "        \n",
    "        questions_for_prediction = \\\n",
    "        self.questions.loc[~self.questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        \n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def _filter_question_by_date(self, questions, start_date, end_date):\n",
    "        mask = \\\n",
    "        (questions['questions_date_added'] > start_date) & \\\n",
    "        (questions['questions_date_added'] <= end_date)\n",
    "        \n",
    "        return questions.loc[mask]\n",
    "        \n",
    "    def recommend_by_pro_id_general(self,\n",
    "                                    professional_id,\n",
    "                                    num_prediction=8):\n",
    "        questions_for_prediction = self._filter_question_by_pro(professional_id)\n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        \n",
    "        return questions_for_prediction\n",
    "    \n",
    "    def recommend_by_pro_id_frequency_date_range(self,\n",
    "                                                 professional_id,\n",
    "                                                 start_date,\n",
    "                                                 end_date,\n",
    "                                                 num_prediction=8):\n",
    "        questions_for_prediction = \\\n",
    "        self._filter_question_by_pro(professional_id)\n",
    "        \n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        questions_for_prediction = self._filter_question_by_date(\n",
    "            questions_for_prediction, start_date, end_date)\n",
    "        \n",
    "        score = self.model.predict(\n",
    "            professional_id,\n",
    "            questions_for_prediction['questions_id_num'].values.tolist(), \n",
    "            item_features=self.questions_features,\n",
    "            user_features=self.professionals_features)\n",
    "        \n",
    "        questions_for_prediction['recommendation_score'] = score\n",
    "        questions_for_prediction = questions_for_prediction.sort_values(\n",
    "            by='recommendation_score', ascending=False)[:num_prediction]\n",
    "        return questions_for_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put it all together**: Now we defined all our important class file. Let's use each of these class and build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# instiate all class instance\n",
    "cv_data_prep = CareerVillageDataPreparation()\n",
    "light_fm_data_prep = LightFMDataPrep()\n",
    "train_lightfm = TrainLightFM()\n",
    "\n",
    "# process raw data\n",
    "df_questions_p, df_professionals_p, df_merge_p = \\\n",
    "cv_data_prep.prepare(\n",
    "    df_professionals,df_students,\n",
    "    df_questions,df_answers,\n",
    "    df_tags,df_tag_questions,df_tag_users,\n",
    "    df_question_scores)\n",
    "\n",
    "# Additional lines\n",
    "# df_questions_p #questions_date_added #students_date_joined\n",
    "df_questions_p['questions_date_added'] = pd.to_datetime(df_questions_p['questions_date_added']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_questions_p['students_date_joined'] = pd.to_datetime(df_questions_p['students_date_joined']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_professionals_p #professionals_date_joined\n",
    "df_professionals_p['professionals_date_joined'] = pd.to_datetime(df_professionals_p['professionals_date_joined']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_merge_p #answers_date_added #questions_date_added\n",
    "df_merge_p['answers_date_added'] = pd.to_datetime(df_merge_p['answers_date_added']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_merge_p['questions_date_added'] = pd.to_datetime(df_merge_p['questions_date_added']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# prepare data for lightfm \n",
    "interactions, weights, \\\n",
    "questions_features, professional_features = \\\n",
    "light_fm_data_prep.fit(\n",
    "    df_questions_p, df_professionals_p, df_merge_p)\n",
    "\n",
    "# finally build and trian our model\n",
    "model = train_lightfm.fit(interactions,\n",
    "                          weights,\n",
    "                          questions_features,\n",
    "                          professional_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Do you see, how easy it was for building our model. We can surely apply this idea when putting the model into production. Now we are going to see some real recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation for professional: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_id_num</th>\n",
       "      <th>tag_questions_question_id</th>\n",
       "      <th>questions_tag_name</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>students_id</th>\n",
       "      <th>students_location</th>\n",
       "      <th>students_date_joined</th>\n",
       "      <th>students_id_num</th>\n",
       "      <th>question_features</th>\n",
       "      <th>recommendation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>2019-01-08 20:47:44</td>\n",
       "      <td>How long does it take to become a Detective?</td>\n",
       "      <td>#law #criminal-justice #lawyer #police #law-en...</td>\n",
       "      <td>2423</td>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>police,law,law-enforcement,criminal-justice,la...</td>\n",
       "      <td>9515b833b2ac4092a8b1a8cdb380781f</td>\n",
       "      <td>2</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>2019-01-08 20:35:58</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>(2423, [police, law, law-enforcement, criminal...</td>\n",
       "      <td>-2.365361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17184</th>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>2019-01-10 01:48:47</td>\n",
       "      <td>What types of Detectives are there?</td>\n",
       "      <td>#law #criminal-justice #lawyer #law-enforcemen...</td>\n",
       "      <td>17184</td>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>police,law,law-enforcement,criminal-justice,la...</td>\n",
       "      <td>570ca25a625d461abffac230ea110db5</td>\n",
       "      <td>2</td>\n",
       "      <td>941ae126a59745fa9b4556293b38c1fb</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>2019-01-08 20:35:58</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>(17184, [police, law, law-enforcement, crimina...</td>\n",
       "      <td>-2.387972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>d7601a6cc1d04e61aaa16c95cbd0b128</td>\n",
       "      <td>2018-10-03 14:04:13</td>\n",
       "      <td>I want to be a police officer or a police disp...</td>\n",
       "      <td>#police-officer #law #law-enforcement #crimina...</td>\n",
       "      <td>9778</td>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>police,police-officer,law,law-enforcement,crim...</td>\n",
       "      <td>776e22d9eb1045eb8a9771eb015e8ddf</td>\n",
       "      <td>2</td>\n",
       "      <td>d7601a6cc1d04e61aaa16c95cbd0b128</td>\n",
       "      <td>Olney, Illinois</td>\n",
       "      <td>2018-10-03 14:01:25</td>\n",
       "      <td>29951.0</td>\n",
       "      <td>(9778, [police, police-officer, law, law-enfor...</td>\n",
       "      <td>-2.730303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-04 16:32:58</td>\n",
       "      <td>Do you go to college, then B.L.E.T( Basic Law ...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>16214</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>2</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(16214, [police, law, law-enforcement])</td>\n",
       "      <td>-2.759122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18126</th>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-04 16:34:56</td>\n",
       "      <td>Do you need law enforcement background such as...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>18126</td>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>4</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(18126, [police, law, law-enforcement])</td>\n",
       "      <td>-2.762117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872</th>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>43f813594dd44e16843ecae4e2362ead</td>\n",
       "      <td>2015-03-23 21:17:34</td>\n",
       "      <td>What majors would fit a law enforcement career?</td>\n",
       "      <td>Im asking this question because I've heard tha...</td>\n",
       "      <td>18872</td>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>c3e6e57cb27b4134be9b8608a711e2fc</td>\n",
       "      <td>4</td>\n",
       "      <td>43f813594dd44e16843ecae4e2362ead</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>2015-03-23 21:09:01</td>\n",
       "      <td>3322.0</td>\n",
       "      <td>(18872, [police, law, law-enforcement])</td>\n",
       "      <td>-2.796726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10534</th>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-05 15:42:36</td>\n",
       "      <td>Is there any required college courses to becom...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>10534</td>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>2</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(10534, [police, law, law-enforcement])</td>\n",
       "      <td>-2.803918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18947</th>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-05 15:39:53</td>\n",
       "      <td>Could I go straight into Law Enforcememt, when...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>18947</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>4</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(18947, [police, law, law-enforcement])</td>\n",
       "      <td>-2.833616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions_id               questions_author_id  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f  941ae126a59745fa9b4556293b38c1fb   \n",
       "17184  570ca25a625d461abffac230ea110db5  941ae126a59745fa9b4556293b38c1fb   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf  d7601a6cc1d04e61aaa16c95cbd0b128   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "18126  6c0079d59ae74c1388045fecbe585570  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc  43f813594dd44e16843ecae4e2362ead   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "\n",
       "      questions_date_added                                    questions_title  \\\n",
       "2423   2019-01-08 20:47:44       How long does it take to become a Detective?   \n",
       "17184  2019-01-10 01:48:47                What types of Detectives are there?   \n",
       "9778   2018-10-03 14:04:13  I want to be a police officer or a police disp...   \n",
       "16214  2016-05-04 16:32:58  Do you go to college, then B.L.E.T( Basic Law ...   \n",
       "18126  2016-05-04 16:34:56  Do you need law enforcement background such as...   \n",
       "18872  2015-03-23 21:17:34    What majors would fit a law enforcement career?   \n",
       "10534  2016-05-05 15:42:36  Is there any required college courses to becom...   \n",
       "18947  2016-05-05 15:39:53  Could I go straight into Law Enforcememt, when...   \n",
       "\n",
       "                                          questions_body  questions_id_num  \\\n",
       "2423   #law #criminal-justice #lawyer #police #law-en...              2423   \n",
       "17184  #law #criminal-justice #lawyer #law-enforcemen...             17184   \n",
       "9778   #police-officer #law #law-enforcement #crimina...              9778   \n",
       "16214  I am an explorer and is trying to set my caree...             16214   \n",
       "18126  I am an explorer and is trying to set my caree...             18126   \n",
       "18872  Im asking this question because I've heard tha...             18872   \n",
       "10534  I am an explorer and is trying to set my caree...             10534   \n",
       "18947  I am an explorer and is trying to set my caree...             18947   \n",
       "\n",
       "              tag_questions_question_id  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f   \n",
       "17184  570ca25a625d461abffac230ea110db5   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc   \n",
       "18126  6c0079d59ae74c1388045fecbe585570   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe   \n",
       "\n",
       "                                      questions_tag_name  \\\n",
       "2423   police,law,law-enforcement,criminal-justice,la...   \n",
       "17184  police,law,law-enforcement,criminal-justice,la...   \n",
       "9778   police,police-officer,law,law-enforcement,crim...   \n",
       "16214                         police,law,law-enforcement   \n",
       "18126                         police,law,law-enforcement   \n",
       "18872                         police,law,law-enforcement   \n",
       "10534                         police,law,law-enforcement   \n",
       "18947                         police,law,law-enforcement   \n",
       "\n",
       "                                     id  score  \\\n",
       "2423   9515b833b2ac4092a8b1a8cdb380781f      2   \n",
       "17184  570ca25a625d461abffac230ea110db5      2   \n",
       "9778   776e22d9eb1045eb8a9771eb015e8ddf      2   \n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc      2   \n",
       "18126  6c0079d59ae74c1388045fecbe585570      4   \n",
       "18872  c3e6e57cb27b4134be9b8608a711e2fc      4   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20      2   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe      4   \n",
       "\n",
       "                            students_id           students_location  \\\n",
       "2423   941ae126a59745fa9b4556293b38c1fb         Oakland, California   \n",
       "17184  941ae126a59745fa9b4556293b38c1fb         Oakland, California   \n",
       "9778   d7601a6cc1d04e61aaa16c95cbd0b128             Olney, Illinois   \n",
       "16214  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "18126  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "18872  43f813594dd44e16843ecae4e2362ead     Los Angeles, California   \n",
       "10534  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "18947  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "\n",
       "      students_date_joined  students_id_num  \\\n",
       "2423   2019-01-08 20:35:58          30755.0   \n",
       "17184  2019-01-08 20:35:58          30755.0   \n",
       "9778   2018-10-03 14:01:25          29951.0   \n",
       "16214  2016-05-02 16:37:52           7103.0   \n",
       "18126  2016-05-02 16:37:52           7103.0   \n",
       "18872  2015-03-23 21:09:01           3322.0   \n",
       "10534  2016-05-02 16:37:52           7103.0   \n",
       "18947  2016-05-02 16:37:52           7103.0   \n",
       "\n",
       "                                       question_features  recommendation_score  \n",
       "2423   (2423, [police, law, law-enforcement, criminal...             -2.365361  \n",
       "17184  (17184, [police, law, law-enforcement, crimina...             -2.387972  \n",
       "9778   (9778, [police, police-officer, law, law-enfor...             -2.730303  \n",
       "16214            (16214, [police, law, law-enforcement])             -2.759122  \n",
       "18126            (18126, [police, law, law-enforcement])             -2.762117  \n",
       "18872            (18872, [police, law, law-enforcement])             -2.796726  \n",
       "10534            (10534, [police, law, law-enforcement])             -2.803918  \n",
       "18947            (18947, [police, law, law-enforcement])             -2.833616  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define our recommender class\n",
    "lightfm_recommendations = LightFMRecommendations(\n",
    "    model,\n",
    "    professional_features,questions_features,\n",
    "    df_questions_p, df_professionals_p, df_merge_p)\n",
    "\n",
    "# let's what our model predict for user id 3\n",
    "print(\"Recommendation for professional: \" + str(3))\n",
    "display(lightfm_recommendations.recommend_by_pro_id_general(3)[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for professionals (question from 2016-1-1 to 2016-12-31): 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_id_num</th>\n",
       "      <th>tag_questions_question_id</th>\n",
       "      <th>questions_tag_name</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>students_id</th>\n",
       "      <th>students_location</th>\n",
       "      <th>students_date_joined</th>\n",
       "      <th>students_id_num</th>\n",
       "      <th>question_features</th>\n",
       "      <th>recommendation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16214</th>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-04 16:32:58</td>\n",
       "      <td>Do you go to college, then B.L.E.T( Basic Law ...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>16214</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>ccb15b06a96a4bcfb4d5844550af25cc</td>\n",
       "      <td>2</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(16214, [police, law, law-enforcement])</td>\n",
       "      <td>-2.759122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18126</th>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-04 16:34:56</td>\n",
       "      <td>Do you need law enforcement background such as...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>18126</td>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>6c0079d59ae74c1388045fecbe585570</td>\n",
       "      <td>4</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(18126, [police, law, law-enforcement])</td>\n",
       "      <td>-2.762117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10534</th>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-05 15:42:36</td>\n",
       "      <td>Is there any required college courses to becom...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>10534</td>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>322afc67ac1848188a4a6d2bf5c51b20</td>\n",
       "      <td>2</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(10534, [police, law, law-enforcement])</td>\n",
       "      <td>-2.803918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18947</th>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>2016-05-05 15:39:53</td>\n",
       "      <td>Could I go straight into Law Enforcememt, when...</td>\n",
       "      <td>I am an explorer and is trying to set my caree...</td>\n",
       "      <td>18947</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>police,law,law-enforcement</td>\n",
       "      <td>cdd0b274ec8f4122a39989707342ccfe</td>\n",
       "      <td>4</td>\n",
       "      <td>8a8305d32bd144d5877842dcabdfb6d7</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 16:37:52</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>(18947, [police, law, law-enforcement])</td>\n",
       "      <td>-2.833616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>716e1eb45ae64de29633eacf2ebddc0e</td>\n",
       "      <td>0a49a80de472412988aac14f93b06374</td>\n",
       "      <td>2016-07-22 03:52:32</td>\n",
       "      <td>What are important characteristics of a lawyer?</td>\n",
       "      <td>I was curious about the desirable traits of a ...</td>\n",
       "      <td>1941</td>\n",
       "      <td>716e1eb45ae64de29633eacf2ebddc0e</td>\n",
       "      <td>law-enforcement,law-school,law,lawyer</td>\n",
       "      <td>716e1eb45ae64de29633eacf2ebddc0e</td>\n",
       "      <td>3</td>\n",
       "      <td>0a49a80de472412988aac14f93b06374</td>\n",
       "      <td>Plano, Texas</td>\n",
       "      <td>2016-05-30 21:08:55</td>\n",
       "      <td>11780.0</td>\n",
       "      <td>(1941, [law-enforcement, law-school, law, lawy...</td>\n",
       "      <td>-2.921825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863</th>\n",
       "      <td>9cc2279d1e8e4a1780426bf93d7468ab</td>\n",
       "      <td>779a47c6bd16423992b81dc7b494e763</td>\n",
       "      <td>2016-07-11 00:47:33</td>\n",
       "      <td>What qualifications are needed to be promoted ...</td>\n",
       "      <td>What qualifications are needed to be promoted ...</td>\n",
       "      <td>8863</td>\n",
       "      <td>9cc2279d1e8e4a1780426bf93d7468ab</td>\n",
       "      <td>criminal-justice,police,law-enforcement</td>\n",
       "      <td>9cc2279d1e8e4a1780426bf93d7468ab</td>\n",
       "      <td>6</td>\n",
       "      <td>779a47c6bd16423992b81dc7b494e763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05 22:23:12</td>\n",
       "      <td>13386.0</td>\n",
       "      <td>(8863, [criminal-justice, police, law-enforcem...</td>\n",
       "      <td>-3.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>33da5b42af304513af00f210be56ea68</td>\n",
       "      <td>779a47c6bd16423992b81dc7b494e763</td>\n",
       "      <td>2016-07-05 22:45:34</td>\n",
       "      <td>What do you wish you had known before you went...</td>\n",
       "      <td>I am currently in college and hope to pursue a...</td>\n",
       "      <td>5139</td>\n",
       "      <td>33da5b42af304513af00f210be56ea68</td>\n",
       "      <td>police,law,law-enforcement,criminal-investigat...</td>\n",
       "      <td>33da5b42af304513af00f210be56ea68</td>\n",
       "      <td>4</td>\n",
       "      <td>779a47c6bd16423992b81dc7b494e763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05 22:23:12</td>\n",
       "      <td>13386.0</td>\n",
       "      <td>(5139, [police, law, law-enforcement, criminal...</td>\n",
       "      <td>-3.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22036</th>\n",
       "      <td>c3ea3de927884725a4ddd934fa691422</td>\n",
       "      <td>4ea5755ee38648a684354938b9829b55</td>\n",
       "      <td>2016-05-05 13:33:27</td>\n",
       "      <td>What type of training is required to become a ...</td>\n",
       "      <td>I want to know the type of training needed. #c...</td>\n",
       "      <td>22036</td>\n",
       "      <td>c3ea3de927884725a4ddd934fa691422</td>\n",
       "      <td>criminal-justice,law-enforcement</td>\n",
       "      <td>c3ea3de927884725a4ddd934fa691422</td>\n",
       "      <td>2</td>\n",
       "      <td>4ea5755ee38648a684354938b9829b55</td>\n",
       "      <td>Laurinburg, North Carolina</td>\n",
       "      <td>2016-05-02 14:05:33</td>\n",
       "      <td>7076.0</td>\n",
       "      <td>(22036, [criminal-justice, law-enforcement])</td>\n",
       "      <td>-3.088016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions_id               questions_author_id  \\\n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "18126  6c0079d59ae74c1388045fecbe585570  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe  8a8305d32bd144d5877842dcabdfb6d7   \n",
       "1941   716e1eb45ae64de29633eacf2ebddc0e  0a49a80de472412988aac14f93b06374   \n",
       "8863   9cc2279d1e8e4a1780426bf93d7468ab  779a47c6bd16423992b81dc7b494e763   \n",
       "5139   33da5b42af304513af00f210be56ea68  779a47c6bd16423992b81dc7b494e763   \n",
       "22036  c3ea3de927884725a4ddd934fa691422  4ea5755ee38648a684354938b9829b55   \n",
       "\n",
       "      questions_date_added                                    questions_title  \\\n",
       "16214  2016-05-04 16:32:58  Do you go to college, then B.L.E.T( Basic Law ...   \n",
       "18126  2016-05-04 16:34:56  Do you need law enforcement background such as...   \n",
       "10534  2016-05-05 15:42:36  Is there any required college courses to becom...   \n",
       "18947  2016-05-05 15:39:53  Could I go straight into Law Enforcememt, when...   \n",
       "1941   2016-07-22 03:52:32    What are important characteristics of a lawyer?   \n",
       "8863   2016-07-11 00:47:33  What qualifications are needed to be promoted ...   \n",
       "5139   2016-07-05 22:45:34  What do you wish you had known before you went...   \n",
       "22036  2016-05-05 13:33:27  What type of training is required to become a ...   \n",
       "\n",
       "                                          questions_body  questions_id_num  \\\n",
       "16214  I am an explorer and is trying to set my caree...             16214   \n",
       "18126  I am an explorer and is trying to set my caree...             18126   \n",
       "10534  I am an explorer and is trying to set my caree...             10534   \n",
       "18947  I am an explorer and is trying to set my caree...             18947   \n",
       "1941   I was curious about the desirable traits of a ...              1941   \n",
       "8863   What qualifications are needed to be promoted ...              8863   \n",
       "5139   I am currently in college and hope to pursue a...              5139   \n",
       "22036  I want to know the type of training needed. #c...             22036   \n",
       "\n",
       "              tag_questions_question_id  \\\n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc   \n",
       "18126  6c0079d59ae74c1388045fecbe585570   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe   \n",
       "1941   716e1eb45ae64de29633eacf2ebddc0e   \n",
       "8863   9cc2279d1e8e4a1780426bf93d7468ab   \n",
       "5139   33da5b42af304513af00f210be56ea68   \n",
       "22036  c3ea3de927884725a4ddd934fa691422   \n",
       "\n",
       "                                      questions_tag_name  \\\n",
       "16214                         police,law,law-enforcement   \n",
       "18126                         police,law,law-enforcement   \n",
       "10534                         police,law,law-enforcement   \n",
       "18947                         police,law,law-enforcement   \n",
       "1941               law-enforcement,law-school,law,lawyer   \n",
       "8863             criminal-justice,police,law-enforcement   \n",
       "5139   police,law,law-enforcement,criminal-investigat...   \n",
       "22036                   criminal-justice,law-enforcement   \n",
       "\n",
       "                                     id  score  \\\n",
       "16214  ccb15b06a96a4bcfb4d5844550af25cc      2   \n",
       "18126  6c0079d59ae74c1388045fecbe585570      4   \n",
       "10534  322afc67ac1848188a4a6d2bf5c51b20      2   \n",
       "18947  cdd0b274ec8f4122a39989707342ccfe      4   \n",
       "1941   716e1eb45ae64de29633eacf2ebddc0e      3   \n",
       "8863   9cc2279d1e8e4a1780426bf93d7468ab      6   \n",
       "5139   33da5b42af304513af00f210be56ea68      4   \n",
       "22036  c3ea3de927884725a4ddd934fa691422      2   \n",
       "\n",
       "                            students_id           students_location  \\\n",
       "16214  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "18126  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "10534  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "18947  8a8305d32bd144d5877842dcabdfb6d7  Laurinburg, North Carolina   \n",
       "1941   0a49a80de472412988aac14f93b06374                Plano, Texas   \n",
       "8863   779a47c6bd16423992b81dc7b494e763                         NaN   \n",
       "5139   779a47c6bd16423992b81dc7b494e763                         NaN   \n",
       "22036  4ea5755ee38648a684354938b9829b55  Laurinburg, North Carolina   \n",
       "\n",
       "      students_date_joined  students_id_num  \\\n",
       "16214  2016-05-02 16:37:52           7103.0   \n",
       "18126  2016-05-02 16:37:52           7103.0   \n",
       "10534  2016-05-02 16:37:52           7103.0   \n",
       "18947  2016-05-02 16:37:52           7103.0   \n",
       "1941   2016-05-30 21:08:55          11780.0   \n",
       "8863   2016-07-05 22:23:12          13386.0   \n",
       "5139   2016-07-05 22:23:12          13386.0   \n",
       "22036  2016-05-02 14:05:33           7076.0   \n",
       "\n",
       "                                       question_features  recommendation_score  \n",
       "16214            (16214, [police, law, law-enforcement])             -2.759122  \n",
       "18126            (18126, [police, law, law-enforcement])             -2.762117  \n",
       "10534            (10534, [police, law, law-enforcement])             -2.803918  \n",
       "18947            (18947, [police, law, law-enforcement])             -2.833616  \n",
       "1941   (1941, [law-enforcement, law-school, law, lawy...             -2.921825  \n",
       "8863   (8863, [criminal-justice, police, law-enforcem...             -3.005390  \n",
       "5139   (5139, [police, law, law-enforcement, criminal...             -3.074200  \n",
       "22036       (22036, [criminal-justice, law-enforcement])             -3.088016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# also let's see what our model predicts for professional 3\n",
    "# given questions between two dates\n",
    "print(\"Recommendations for professionals (question from 2016-1-1 to 2016-12-31): \" + str(3))\n",
    "display(lightfm_recommendations.recommend_by_pro_id_frequency_date_range(3,'2016-1-1','2016-12-31')[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can see our recommendations. Also, we can see, the new recommendation class has a method for recommending questions by a frequency of date. This is very helpful for recommending questions to professionals that have set their email frequency to daily or weekly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "**Idea that I tried but don't implemented in this notebook**: \n",
    "* Adding location features: I tried adding location features but somehow it decreases model AUC score to 91% to 84%. That's why I don't use that features.\n",
    "* Adding dates and hearts data: I also tried that but it doesn't improve AUC score. \n",
    "* Correcting spelling error: I tried this method and successfully implemented it. But this is really slow. For that reason, I exluded it. \n",
    "\n",
    "**Idea that I think is important don't implemented in this notebook**: \n",
    "* Adding professionals industry and title as a features. This will inhance our model diversity and will increase overall recommendations score.\n",
    "* CareerVillage should auto correct the hashtags for students questions asking time. This will help the model to match the tags more efficiently. \n",
    "* For those professionals those have choosen email frequency to immediete, we can create another same model just exchange user/item features. I mean train our model by giving questions as users and professionals as items. In this way, we can predict professionals by giving a questions. So that it helps to target daily frequency professionals.\n",
    "\n",
    "Finally we came to end. I want give you a big thank you for reading this notebook. I have provided a very good recommender system for CareerVillage in the notebook. If you find any mistakes or have any suggestions feel free to comment. And don't forget to upvote. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "[1] [Improving Pairwise Learning for Item Recommendation from Implicit Feedback](http://webia.lip6.fr/~gallinar/gallinari/uploads/Teaching/WSDM2014-rendle.pdf)\n",
    "\n",
    "[2] [Content-based filtering](https://towardsdatascience.com/what-are-product-recommendation-engines-and-the-various-versions-of-them-9dcab4ee26d5)\n",
    "\n",
    "[3] [What Is Content-Based Filtering?](https://www.upwork.com/hiring/data/what-is-content-based-filtering/)\n",
    "\n",
    "[4] [What Is Collaborative Filtering?](https://www.upwork.com/hiring/data/how-collaborative-filtering-works/)\n",
    "\n",
    "[5] [Collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)\n",
    "\n",
    "[6] [LightFM model documentation](https://lyst.github.io/lightfm/docs/lightfm.html)\n",
    "\n",
    "[7] [Metadata Embeddings for User and Item Cold-start Recommendations](https://arxiv.org/pdf/1507.08439.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
